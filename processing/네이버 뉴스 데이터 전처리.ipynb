{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models and tokenizer...\n",
      "Using device: cpu\n",
      "Initializing Kiwi...\n",
      "Connecting to Milvus (localhost:19530)...\n",
      "Successfully connected to Milvus.\n",
      "Creating collection 'news_embeddings'...\n",
      "Collection 'news_embeddings' created successfully.\n",
      "Reading CSV file: naver_news_data.csv\n",
      "Successfully read 100 articles from CSV.\n",
      "Starting data processing (Chunking, Embedding)...\n",
      "Processed 50/100 articles...\n",
      "Processed 100/100 articles...\n",
      "Data processing finished. Time taken: 91.87 seconds.\n",
      "Total chunks to insert: 215\n",
      "Inserting 215 entities into 'news_embeddings'...\n",
      "Insertion successful. Primary keys count: 215\n",
      "Flushing data...\n",
      "Data flushed.\n",
      "Creating index (IVF_FLAT) for embedding field...\n",
      "Index created successfully.\n",
      "Waiting for index to build...\n",
      "Index building complete.\n",
      "Loading collection into memory...\n",
      "Collection 'news_embeddings' loaded successfully.\n",
      "\n",
      "--- Milvus processing finished ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from kiwipiepy import Kiwi\n",
    "from pymilvus import connections, utility, FieldSchema, CollectionSchema, DataType, Collection\n",
    "import time # 시간 측정을 위해 추가 (선택적)\n",
    "\n",
    "# --- 1. 설정값 ---\n",
    "CSV_FILE_PATH = 'naver_news_data.csv'  # <<<< CSV 파일 경로를 지정하세요\n",
    "TEXT_COLUMN = 'content'             # 임베딩할 텍스트가 포함된 컬럼 이름\n",
    "METADATA_COLUMNS = ['title', 'datetime', 'summary', 'url'] # 함께 저장할 메타데이터 컬럼들\n",
    "\n",
    "# 임베딩 모델 설정\n",
    "MODEL_NAME = \"klue/bert-base\"\n",
    "\n",
    "# 청킹 설정\n",
    "MAX_TOKENS_PER_CHUNK = 400 # 청크당 최대 토큰 수 (모델 최대 길이보다 작게)\n",
    "# (kiwipiepy는 문장 단위로 나누므로 overlap 개념은 직접 적용 안 함)\n",
    "\n",
    "# Milvus 설정\n",
    "MILVUS_HOST = \"localhost\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "COLLECTION_NAME = \"news_embeddings\" # 새 컬렉션 이름 지정 권장\n",
    "VECTOR_DIM = 768\n",
    "\n",
    "# --- 2. 모델 및 토크나이저, Kiwi 로드 ---\n",
    "print(\"Loading models and tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval() # 평가 모드\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Initializing Kiwi...\")\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# --- 3. Milvus 연결 및 컬렉션 준비 ---\n",
    "print(f\"Connecting to Milvus ({MILVUS_HOST}:{MILVUS_PORT})...\")\n",
    "try:\n",
    "    connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "    print(\"Successfully connected to Milvus.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to Milvus: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 새 스키마 정의 (메타데이터 필드 추가)\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"chunk_text\", dtype=DataType.VARCHAR, max_length=65535), # 청크 텍스트\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=VECTOR_DIM),\n",
    "    FieldSchema(name=\"original_article_id\", dtype=DataType.INT64), # 원본 CSV의 행 index 등\n",
    "    FieldSchema(name=\"chunk_seq_id\", dtype=DataType.INT64),       # 기사 내 청크 순서\n",
    "    # 추가 메타데이터 필드들\n",
    "    FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=1024), # 길이 조절 가능\n",
    "    FieldSchema(name=\"datetime\", dtype=DataType.VARCHAR, max_length=64), # 또는 날짜 타입\n",
    "    FieldSchema(name=\"summary\", dtype=DataType.VARCHAR, max_length=2048), # 길이 조절 가능\n",
    "    FieldSchema(name=\"url\", dtype=DataType.VARCHAR, max_length=2048)      # 길이 조절 가능\n",
    "]\n",
    "schema = CollectionSchema(fields, description=\"Naver News Embeddings with Metadata\")\n",
    "\n",
    "# 컬렉션 생성 또는 가져오기\n",
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    print(f\"Collection '{COLLECTION_NAME}' already exists.\")\n",
    "    collection = Collection(COLLECTION_NAME)\n",
    "else:\n",
    "    print(f\"Creating collection '{COLLECTION_NAME}'...\")\n",
    "    collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
    "    print(f\"Collection '{COLLECTION_NAME}' created successfully.\")\n",
    "\n",
    "# --- 4. 데이터 처리 및 Milvus 삽입 준비 ---\n",
    "print(f\"Reading CSV file: {CSV_FILE_PATH}\")\n",
    "try:\n",
    "    # CSV 인코딩 주의: 'utf-8' 또는 'cp949' 등을 시도\n",
    "    df = pd.read_csv(CSV_FILE_PATH, encoding='utf-8')\n",
    "    print(f\"Successfully read {len(df)} articles from CSV.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {CSV_FILE_PATH}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading CSV file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Milvus에 삽입할 데이터 리스트들 초기화\n",
    "all_chunk_texts = []\n",
    "all_embeddings = []\n",
    "all_original_article_ids = []\n",
    "all_chunk_seq_ids = []\n",
    "all_titles = []\n",
    "all_datetimes = []\n",
    "all_summaries = []\n",
    "all_urls = []\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Starting data processing (Chunking, Embedding)...\")\n",
    "\n",
    "# DataFrame의 각 행(기사) 처리\n",
    "for idx, row in df.iterrows():\n",
    "    article_content = row[TEXT_COLUMN]\n",
    "    article_title = row['title'] # 메타데이터 가져오기\n",
    "    article_datetime = str(row['datetime']) # 문자열로 변환 (필요시)\n",
    "    article_summary = row['summary']\n",
    "    article_url = row['url']\n",
    "\n",
    "    # content가 비어있거나 NaN인 경우 건너뛰기\n",
    "    if not isinstance(article_content, str) or pd.isna(article_content) or not article_content.strip():\n",
    "        print(f\"Skipping article index {idx} due to empty content.\")\n",
    "        continue\n",
    "\n",
    "    # 간단한 전처리 (연속 공백 제거 등)\n",
    "    cleaned_content = re.sub(r'\\s+', ' ', article_content).strip()\n",
    "\n",
    "    # Kiwi를 이용한 문장 분할\n",
    "    sentences = [s.text for s in kiwi.split_into_sents(cleaned_content)]\n",
    "\n",
    "    # 문장을 그룹화하여 청크 생성\n",
    "    current_chunk_sentences = []\n",
    "    current_chunk_length = 0\n",
    "    article_chunks = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
    "        sentence_length = len(sentence_tokens)\n",
    "\n",
    "        if current_chunk_length + sentence_length <= MAX_TOKENS_PER_CHUNK:\n",
    "            current_chunk_sentences.append(sentence)\n",
    "            current_chunk_length += sentence_length + 1\n",
    "        else:\n",
    "            if current_chunk_sentences:\n",
    "                article_chunks.append(\" \".join(current_chunk_sentences))\n",
    "            if sentence_length <= MAX_TOKENS_PER_CHUNK:\n",
    "                current_chunk_sentences = [sentence]\n",
    "                current_chunk_length = sentence_length\n",
    "            else:\n",
    "                # 문장 자체가 너무 긴 경우, 일단 잘릴 것을 감수하고 청크에 넣음\n",
    "                article_chunks.append(sentence)\n",
    "                current_chunk_sentences = []\n",
    "                current_chunk_length = 0\n",
    "    if current_chunk_sentences:\n",
    "        article_chunks.append(\" \".join(current_chunk_sentences))\n",
    "\n",
    "    # 생성된 청크들을 임베딩하고 데이터 준비\n",
    "    with torch.no_grad():\n",
    "        for seq_id, chunk_text in enumerate(article_chunks):\n",
    "            if not chunk_text: continue # 빈 청크 스킵\n",
    "\n",
    "            encoded_input = tokenizer(chunk_text, padding=True, truncation=True, max_length=512, return_tensors='pt').to(device)\n",
    "            try:\n",
    "                model_output = model(**encoded_input)\n",
    "                # Mean Pooling 적용\n",
    "                token_embeddings = model_output[0]\n",
    "                input_mask_expanded = encoded_input['attention_mask'].unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "                sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "                sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "                embedding_vector = (sum_embeddings / sum_mask).cpu().squeeze().tolist()\n",
    "\n",
    "                # 삽입할 데이터 리스트에 추가\n",
    "                all_chunk_texts.append(chunk_text)\n",
    "                all_embeddings.append(embedding_vector)\n",
    "                all_original_article_ids.append(idx) # 원본 DataFrame 인덱스 사용\n",
    "                all_chunk_seq_ids.append(seq_id)\n",
    "                all_titles.append(article_title)\n",
    "                all_datetimes.append(article_datetime)\n",
    "                all_summaries.append(article_summary if isinstance(article_summary, str) else \"\") # NaN 처리\n",
    "                all_urls.append(article_url)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error embedding chunk {seq_id} for article {idx}: {e}\")\n",
    "\n",
    "    if (idx + 1) % 50 == 0: # 50개 기사 처리마다 로그 출력\n",
    "        print(f\"Processed {idx + 1}/{len(df)} articles...\")\n",
    "\n",
    "processing_time = time.time() - start_time\n",
    "print(f\"Data processing finished. Time taken: {processing_time:.2f} seconds.\")\n",
    "print(f\"Total chunks to insert: {len(all_chunk_texts)}\")\n",
    "\n",
    "# --- 5. Milvus 데이터 삽입 ---\n",
    "if not all_chunk_texts:\n",
    "    print(\"No valid data to insert into Milvus.\")\n",
    "else:\n",
    "    # 삽입 형식 준비\n",
    "    entities_to_insert = [\n",
    "        all_chunk_texts,\n",
    "        all_embeddings,\n",
    "        all_original_article_ids,\n",
    "        all_chunk_seq_ids,\n",
    "        all_titles,\n",
    "        all_datetimes,\n",
    "        all_summaries,\n",
    "        all_urls\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        print(f\"Inserting {len(all_chunk_texts)} entities into '{COLLECTION_NAME}'...\")\n",
    "        insert_result = collection.insert(entities_to_insert)\n",
    "        print(f\"Insertion successful. Primary keys count: {len(insert_result.primary_keys)}\")\n",
    "\n",
    "        print(\"Flushing data...\")\n",
    "        collection.flush()\n",
    "        print(\"Data flushed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to insert data into Milvus: {e}\")\n",
    "\n",
    "    # --- 6. 인덱스 생성 및 로드 ---\n",
    "    INDEX_PARAM = {\n",
    "        \"metric_type\": \"L2\",\n",
    "        \"index_type\": \"IVF_FLAT\",\n",
    "        \"params\": {\"nlist\": 128} # 데이터 양에 따라 조절\n",
    "    }\n",
    "\n",
    "    if not collection.has_index():\n",
    "        print(f\"Creating index ({INDEX_PARAM['index_type']}) for embedding field...\")\n",
    "        try:\n",
    "            collection.create_index(field_name=\"embedding\", index_params=INDEX_PARAM)\n",
    "            print(\"Index created successfully.\")\n",
    "            print(\"Waiting for index to build...\")\n",
    "            utility.wait_for_index_building_complete(COLLECTION_NAME)\n",
    "            print(\"Index building complete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create index: {e}\")\n",
    "    else:\n",
    "        print(\"Index already exists.\")\n",
    "\n",
    "    print(\"Loading collection into memory...\")\n",
    "    try:\n",
    "        collection.load()\n",
    "        print(f\"Collection '{COLLECTION_NAME}' loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load collection: {e}\")\n",
    "\n",
    "# --- 7. 연결 종료 (선택적) ---\n",
    "# connections.disconnect(\"default\")\n",
    "\n",
    "print(\"\\n--- Milvus processing finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
