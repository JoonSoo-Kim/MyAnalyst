{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymilvus in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.5.6)\n",
      "Requirement already satisfied: openai in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.68.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.50.1)\n",
      "Requirement already satisfied: torch in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: setuptools>69 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pymilvus) (78.1.0)\n",
      "Requirement already satisfied: grpcio<=1.67.1,>=1.49.1 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pymilvus) (1.67.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pymilvus) (6.30.1)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pymilvus) (1.1.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pymilvus) (5.10.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pymilvus) (2.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.2.4->pymilvus) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pymilvus openai transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model and tokenizer...\n",
      "Using device for embedding: cpu\n",
      "RAG 시스템을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pymilvus import connections, Collection, utility, FieldSchema, CollectionSchema, DataType\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import time\n",
    "\n",
    "# --- 1. 설정값 ---\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI 설정\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"오류: OPENAI_API_KEY 환경 변수를 설정해주세요.\")\n",
    "    exit()\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\") # 사용할 OpenAI 모델, 기본값 설정\n",
    "\n",
    "# 임베딩 모델 설정 (Milvus 저장 시 사용했던 모델과 동일해야 함)\n",
    "EMBEDDING_MODEL_NAME = os.getenv(\"EMBEDDING_MODEL_NAME\", \"klue/bert-base\")\n",
    "VECTOR_DIM = int(os.getenv(\"VECTOR_DIM\", \"768\"))\n",
    "\n",
    "# Milvus 설정\n",
    "MILVUS_HOST = os.getenv(\"MILVUS_HOST\", \"localhost\")\n",
    "MILVUS_PORT = os.getenv(\"MILVUS_PORT\", \"19530\")\n",
    "# COLLECTION_NAME = \"celltrion_embedding\" # <<<< 검색할 컬렉션 이름\n",
    "# 만약 여러 컬렉션을 검색해야 한다면 리스트로 관리\n",
    "COLLECTION_NAMES = [\"celltrion_embeddings\", \"news_embeddings\"]\n",
    "\n",
    "# 검색 설정\n",
    "SEARCH_TOP_K = 20 # Milvus에서 검색할 상위 K개 결과\n",
    "SEARCH_PARAMS = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nprobe\": 10} # IVF_FLAT 인덱스 사용 시 nprobe 값 조절\n",
    "    # \"params\": {\"ef\": 64} # HNSW 인덱스 사용 시 ef 값 조절\n",
    "}\n",
    "\n",
    "# --- 2. 모델 및 토크나이저 로드 ---\n",
    "print(\"Loading embedding model and tokenizer...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)\n",
    "    embedding_model = AutoModel.from_pretrained(EMBEDDING_MODEL_NAME)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    embedding_model.to(device)\n",
    "    embedding_model.eval() # 평가 모드\n",
    "    print(f\"Using device for embedding: {device}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading embedding model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. 유틸리티 함수 ---\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    \"\"\"Mean Pooling 계산 함수\"\"\"\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"주어진 텍스트의 임베딩 벡터를 반환 (NumPy Array)\"\"\"\n",
    "    try:\n",
    "        encoded_input = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            model_output = embedding_model(**encoded_input)\n",
    "        embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        return embedding.cpu().numpy().flatten() # NumPy 배열로 변환 후 flatten\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embedding for text '{text[:50]}...': {e}\")\n",
    "        return None\n",
    "\n",
    "# search_milvus 함수 정의\n",
    "def search_milvus(query_vector, collection_names_list, top_k_total):\n",
    "    \"\"\"\n",
    "    Milvus의 여러 컬렉션에서 관련성 높은 청크를 검색하고 결과를 병합합니다.\n",
    "    (결과 처리 시 컬렉션별 필드 접근 분기 적용)\n",
    "    \"\"\"\n",
    "    all_retrieved_chunks = []\n",
    "    try:\n",
    "        if not connections.has_connection(\"default\"):\n",
    "             connections.connect(\"default\", host=MILVUS_HOST, port=MILVUS_PORT)\n",
    "\n",
    "        for c_name in collection_names_list:\n",
    "            # --- 컬렉션 확인, 로드, Output Fields 정의 (이전과 동일) ---\n",
    "            print(f\"\\nSearching in collection: '{c_name}'...\")\n",
    "            # ... (collection 존재 확인, load 로직 동일) ...\n",
    "            collection = Collection(c_name)\n",
    "            try:\n",
    "                print(f\"  Ensuring collection '{c_name}' is loaded...\")\n",
    "                collection.load()\n",
    "                utility.wait_for_loading_complete(c_name)\n",
    "                print(f\"  Collection '{c_name}' is ready for search.\")\n",
    "            except Exception as load_err:\n",
    "                print(f\"  Error loading collection '{c_name}': {load_err}\")\n",
    "                continue\n",
    "\n",
    "            current_output_fields = []\n",
    "            text_field_for_this_collection = \"\"\n",
    "            if c_name == \"celltrion_embeddings\":\n",
    "                 text_field_for_this_collection = \"text\"\n",
    "                 current_output_fields = [text_field_for_this_collection]\n",
    "            elif c_name == \"news_embeddings\":\n",
    "                 text_field_for_this_collection = \"chunk_text\"\n",
    "                 current_output_fields = [\n",
    "                     text_field_for_this_collection, \"original_article_id\",\n",
    "                     \"chunk_seq_id\", \"title\", \"datetime\", \"summary\", \"url\"\n",
    "                 ]\n",
    "            else:\n",
    "                 print(f\"  Warning: Unknown collection '{c_name}'. Skipping search.\")\n",
    "                 continue\n",
    "\n",
    "            # --- 검색 실행 (이전과 동일) ---\n",
    "            try:\n",
    "                search_results = collection.search(\n",
    "                    data=[query_vector.tolist()],\n",
    "                    anns_field=\"embedding\",\n",
    "                    param=SEARCH_PARAMS,\n",
    "                    limit=top_k_total,\n",
    "                    output_fields=current_output_fields\n",
    "                )\n",
    "\n",
    "                # --- 결과 처리 (★★ 컬렉션별 필드 접근 분기 적용 ★★) ---\n",
    "                if search_results and search_results[0]:\n",
    "                    for hit in search_results[0]:\n",
    "                        try:\n",
    "                            hit_id = hit.id\n",
    "                            hit_score = hit.distance\n",
    "                            entity = hit.entity # entity 객체 가져오기\n",
    "\n",
    "                            # 공통 필드 및 기본값으로 chunk_data 초기화\n",
    "                            chunk_data = {\n",
    "                                \"collection\": c_name,\n",
    "                                \"id\": hit_id,\n",
    "                                \"score\": hit_score,\n",
    "                                # 텍스트 필드는 항상 요청되므로 getattr 사용 가능\n",
    "                                \"text\": getattr(entity, text_field_for_this_collection, \"\"),\n",
    "                                # source_type 기본값 설정 (스키마에 없으므로)\n",
    "                                \"source_type\": c_name\n",
    "                            }\n",
    "\n",
    "                            # ★★★ 컬렉션에 따라 추가 필드 접근 ★★★\n",
    "                            if c_name == \"news_embeddings\":\n",
    "                                # news_embeddings 스키마에 있고 output_fields로 요청한 필드만 접근\n",
    "                                chunk_data[\"title\"] = getattr(entity, \"title\", \"\")\n",
    "                                chunk_data[\"url\"] = getattr(entity, \"url\", \"\")\n",
    "                                chunk_data[\"original_article_id\"] = getattr(entity, \"original_article_id\", None)\n",
    "                                chunk_data[\"chunk_seq_id\"] = getattr(entity, \"chunk_seq_id\", None)\n",
    "                                chunk_data[\"datetime\"] = getattr(entity, \"datetime\", \"\")\n",
    "                                chunk_data[\"summary\"] = getattr(entity, \"summary\", \"\")\n",
    "                                # 만약 news 스키마에 source_type이 있다면 여기서 덮어쓰기\n",
    "                                # chunk_data[\"source_type\"] = getattr(entity, \"source_type\", c_name)\n",
    "\n",
    "                            elif c_name == \"celltrion_embeddings\":\n",
    "                                # celltrion_embeddings 스키마에는 추가 메타데이터 필드가 없음\n",
    "                                # 따라서 여기서 접근할 필드 없음\n",
    "                                pass\n",
    "                                # 만약 celltrion 스키마에 source_type이 있다면 여기서 덮어쓰기\n",
    "                                # chunk_data[\"source_type\"] = getattr(entity, \"source_type\", c_name)\n",
    "\n",
    "                            all_retrieved_chunks.append(chunk_data)\n",
    "\n",
    "                        except Exception as process_err:\n",
    "                            # 개별 hit 처리 중 예외 발생 시 로그 남기고 계속\n",
    "                            print(f\"  Warning: Error processing hit {getattr(hit, 'id', 'N/A')} in {c_name}: {process_err}\")\n",
    "                            continue # 다음 hit으로 넘어감\n",
    "\n",
    "                    print(f\"  Found {len(search_results[0])} results in '{c_name}'.\")\n",
    "\n",
    "            except Exception as search_err:\n",
    "                print(f\"  Error searching collection '{c_name}': {search_err}\")\n",
    "\n",
    "        # --- 결과 취합 후 정렬 및 제한 (이하 동일) ---\n",
    "        if all_retrieved_chunks:\n",
    "            all_retrieved_chunks.sort(key=lambda x: x['score'])\n",
    "            print(f\"\\nTotal results from all collections: {len(all_retrieved_chunks)}\")\n",
    "            final_chunks = all_retrieved_chunks[:top_k_total]\n",
    "            print(f\"Returning top {len(final_chunks)} overall results.\")\n",
    "            return final_chunks\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Milvus search process: {e}\")\n",
    "        return []\n",
    "\n",
    "def format_context(retrieved_chunks):\n",
    "    \"\"\"검색된 청크들을 LLM 프롬프트에 넣기 좋은 형태의 문자열로 변환\"\"\"\n",
    "    context_str = \"\"\n",
    "    for i, chunk in enumerate(retrieved_chunks):\n",
    "        context_str += f\"--- 문서 {i+1} (ID: {chunk['id']}, 출처: {chunk.get('title', 'N/A')}) ---\\n\"\n",
    "        context_str += chunk.get('text', '') + \"\\n\\n\"\n",
    "    return context_str.strip()\n",
    "\n",
    "def ask_llm(query, context):\n",
    "    \"\"\"LLM에게 질문과 컨텍스트를 전달하고 답변을 받음\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "[배경 정보]\n",
    "\n",
    "- 분석 대상 기업: 셀트리온\n",
    "- 현재 시점: 2025년 1월 1일\n",
    "\n",
    "[목표]\n",
    "\n",
    "셀트리온의 24년 4분기 실적 분석 및 향후 전망에 대한 종합적인 기업 분석 보고서를 생성하는 것입니다.\n",
    "\n",
    "[보고서 작성 가이드라인]\n",
    "\n",
    "- 정보 출처 명확화: 보고서의 모든 내용은 오직 RAG를 통해 제공된 컨텍스트에만 근거해야 합니다. 컨텍스트에 명시적으로 언급되지 않은 외부 정보, 추측, 또는 개인적인 의견을 포함하지 마십시오.\n",
    "- 객관성 유지: 사실에 기반하여 객관적이고 중립적인 톤으로 서술하십시오.\n",
    "- 구조화: 아래 제시된 구조에 따라 정보를 논리적으로 구성하여 보고서를 작성하십시오.\n",
    "\n",
    "[생성할 보고서의 구조 및 포함 내용 지침]\n",
    "\n",
    "다음 구조를 따라 보고서를 작성하되, 각 섹션에 해당하는 내용을 제공된 컨텍스트(공시, 뉴스 기사)에서 찾아서 요약하고 기술하십시오.\n",
    "\n",
    "1. 보고서 요약 (Executive Summary):\n",
    "    - 컨텍스트에 기반한 셀트리온 4Q24 실적의 주요 특징 요약.\n",
    "    - 컨텍스트에서 파악된 향후 사업 방향 또는 전망에 대한 핵심 내용 요약.\n",
    "2. 2024년 4분기 실적 분석:\n",
    "    - 실적 요인 분석: 공시 내용이나 뉴스 기사에서 언급된 4Q24 실적의 주요 변동 요인(긍정적/부정적 요인 모두)을 설명. (예: 특정 제품의 판매 호조/부진, 비용 증가/감소 요인, 일회성 손익 발생 등 공식적으로 언급된 내용)\n",
    "3. 주요 사업 및 제품 동향:\n",
    "    - 제품 관련 소식: 컨텍스트에서 언급된 주요 제품(예: 램시마SC, 유플라이마, 베그젤마, 짐펜트라, 스테키마 등) 관련 최신 동향(예: 주요 시장 출시/허가 현황, 판매 관련 언급, 생산 관련 소식 등)을 요약.\n",
    "    - R&D 및 파이프라인: 컨텍스트에서 찾을 수 있는 신약 개발 진행 상황, 임상 결과 발표, 기술 도입 등 R&D 관련 중요 업데이트 사항을 기술.\n",
    "    - CMO 사업: 위탁생산(CMO) 관련 계약, 생산 등 컨텍스트 내 관련 정보를 요약.\n",
    "    - 기타 사업: 합병 관련 진행 상황 및 시너지 창출 노력 등 컨텍스트 내 기타 중요 사업 내용을 포함.\n",
    "4. 시장 환경 및 전략 방향:\n",
    "    - 주요 시장 활동: 컨텍스트에 나타난 주요 시장(예: 미국, 유럽)에서의 활동 내용(예: 신제품 출시, 허가 신청, 마케팅 활동, 시장 경쟁 관련 언급 등)을 요약.\n",
    "    - 회사의 공식 전략: 컨텍스트의 공시나 보도자료 등에서 발표된 회사의 주요 경영 전략, 투자 계획, 파트너십 체결 등 내용을 정리.\n",
    "5. 향후 전망 (공식 발표 기반):\n",
    "    - 회사의 공식 입장/계획: 컨텍스트에서 확인되는 2025년 사업 계획, 목표, 신제품 출시 예정, 성장 전략 등 회사에서 공식적으로 발표한 향후 전망 관련 내용을 요약. (애널리스트의 예측이 아닌, 회사의 발표 내용 중심)\n",
    "    - 미래 성과 영향 요인: 컨텍스트 정보를 바탕으로 향후 실적에 영향을 미칠 수 있는 주요 요인(예: 신제품 성과 기대, 진행 중인 R&D 중요성, 시장 환경 변화 등 공식 발표나 뉴스에서 강조된 내용)을 정리.\n",
    "6. 기타 참고사항:\n",
    "    - 컨텍스트(공시, 뉴스 기사)에서 언급된 기타 중요 정보, 잠재적 위험 요인 또는 기회 요인 등을 객관적으로 요약. (투자 추천이나 가치 판단은 제외)\n",
    "\n",
    "[보고서 평가 기준]\n",
    "\n",
    "평가 목표: 생성된 보고서가 주어진 컨텍스트(셀트리온 4Q24 공시 자료 및 관련 뉴스 기사)의 정보를 얼마나 정확하고 충실하게, 그리고 구조적으로 잘 요약했는지 평가합니다.\n",
    "\n",
    "종합 평가 기준 (모든 목차 공통 적용):\n",
    "\n",
    "1. 컨텍스트 충실성 (Context Fidelity): 보고서의 모든 내용이 오직 제공된 컨텍스트 정보에만 기반하는가? 외부 정보나 환각(Hallucination)은 없는가? (가장 중요)\n",
    "2. 구조 준수성 (Structural Adherence): 제시된 6가지 목차 구조를 정확히 따르고 있는가?\n",
    "3. 객관성 및 톤 (Objectivity & Tone): 보고서 전체적으로 객관적이고 사실 기반의 중립적인 톤을 유지하는가? 추측이나 주관적 평가는 배제되었는가?\n",
    "4. 명확성 및 가독성 (Clarity & Readability): 사용된 언어가 명확하고 이해하기 쉬운가? 정보가 각 목차 내에서 논리적으로 구성되어 있는가?\n",
    "\n",
    "목차별 세부 평가 기준:\n",
    "\n",
    "1. 보고서 요약 (Executive Summary)\n",
    "\n",
    "- 핵심 내용 반영도: 보고서 본문(2~6번 목차)의 핵심 내용(4Q24 실적 주요 특징, 향후 전망 핵심)을 정확하게 요약하고 있는가?\n",
    "- 정확성 및 일관성: 요약된 내용이 컨텍스트 및 보고서 본문의 내용과 일치하며 왜곡이 없는가?\n",
    "- 간결성: 핵심 내용을 간결하게 전달하는가? 불필요하게 상세하지 않은가?\n",
    "- 포괄성: 실적 측면과 전망 측면을 균형 있게 포함하는가?\n",
    "\n",
    "2. 2024년 4분기 실적 분석 (4Q24 Performance Review)\n",
    "\n",
    "- 실적 요인 분석 정확성: 실적 변동 요인(매출 동인, 비용 요인 등) 설명이 컨텍스트(공시, 뉴스) 내용과 정확히 일치하는가?\n",
    "- 실적 요인 분석 완전성: 컨텍스트에서 언급된 *중요한* 실적 변동 요인을 충분히 다루고 있는가?\n",
    "- 컨텍스트 기반: 분석 내용이 컨텍스트 정보에만 근거하며 외부 해석이 배제되었는가?\n",
    "\n",
    "3. 주요 사업 및 제품 동향 (Business & Product Developments)\n",
    "\n",
    "- 정보 정확성: 제품 동향, R&D 업데이트, CMO 관련 기술 내용이 컨텍스트 정보와 사실적으로 일치하는가?\n",
    "- 정보 완전성: 컨텍스트에서 언급된 주요 제품, R&D, CMO 관련 *중요* 업데이트 사항을 누락 없이 포함했는가?\n",
    "- 관련성: 보고서 목차의 주제(사업 및 제품 동향)와 관련된 내용을 충실히 담고 있는가?\n",
    "- 컨텍스트 기반: 내용이 컨텍스트(공시, 뉴스)에서 직접 확인 가능한 정보인가?\n",
    "\n",
    "4. 시장 환경 및 전략 방향 (Market Environment & Strategy)\n",
    "\n",
    "- 정보 정확성: 주요 시장(미국, 유럽 등) 활동 및 회사 전략(합병 시너지, 파트너십 등)에 대한 설명이 컨텍스트 정보와 일치하는가?\n",
    "- 정보 완전성: 컨텍스트에서 강조된 주요 시장 활동 및 전략 방향을 충분히 포함하고 있는가?\n",
    "- 관련성: 내용이 시장 환경 및 회사의 전략적 움직임에 초점을 맞추고 있는가?\n",
    "- 컨텍스트 기반: 설명이 컨텍스트에서 제공된 정보의 범위를 벗어나지 않는가?\n",
    "\n",
    "5. 향후 전망 (공식 발표 기반) (Future Outlook - Based on Official Statements)\n",
    "\n",
    "- 공식 입장 정확성: 회사의 공식적인 향후 계획, 목표, 신제품 출시 일정 등을 컨텍스트 내용 그대로 정확하게 전달하는가?\n",
    "- 공식 입장 완전성: 컨텍스트에서 언급된 회사의 *주요* 공식 전망 내용을 포함하고 있는가?\n",
    "- 출처 명확성: 해당 내용이 회사의 '공식 발표'에 기반한 것임을 명확히 인지할 수 있게 서술되었는가? (추측성 서술과 구분되는가?)\n",
    "- 컨텍스트 기반: 회사의 공식 발표 내용을 왜곡하거나 과장하지 않았는가?\n",
    "\n",
    "6. 기타 참고사항 (Key Considerations - Based on Public Info)\n",
    "\n",
    "- 정보 정확성: 언급된 참고사항(리스크, 기회 등)이 컨텍스트 정보에 사실적으로 기반하는가?\n",
    "- 정보 완전성: 컨텍스트 내 다른 목차에 포함되지 않은 *중요한* 기타 정보, 리스크, 기회 요인을 포함하는가?\n",
    "- 객관성: 투자 추천이나 주관적 가치 판단 없이, 사실 정보를 객관적으로 전달하는가?\n",
    "- 관련성: 내용이 '기타 참고사항'으로서의 관련성을 가지는가?\n",
    "- 컨텍스트 기반: 내용이 컨텍스트에서 직접 확인 가능한 정보인가?\n",
    "\n",
    "\n",
    "[컨텍스트 정보]\n",
    "{context if context else \"제공된 컨텍스트 정보가 없습니다.\"}\n",
    "\n",
    "[사용자 질문]\n",
    "{query}\n",
    "\n",
    "[답변]\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        response = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on provided context in Korean.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7, # 답변의 창의성 조절 (0에 가까울수록 결정적)\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling OpenAI API: {e}\")\n",
    "        return \"OpenAI API 호출 중 오류가 발생했습니다.\"\n",
    "\n",
    "# --- 4. RAG 파이프라인 실행 ---\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_query = input(\"\\n질문을 입력하세요 (종료하려면 'exit' 입력): \")\n",
    "        if user_query.lower() == 'exit':\n",
    "            break\n",
    "        if not user_query:\n",
    "            continue\n",
    "\n",
    "        # 1. 쿼리 임베딩\n",
    "        print(\"Embedding your query...\")\n",
    "        start_embed_time = time.time()\n",
    "        query_embedding = get_embedding(user_query)\n",
    "        embed_time = time.time() - start_embed_time\n",
    "        if query_embedding is None:\n",
    "            print(\"쿼리 임베딩 중 오류가 발생했습니다.\")\n",
    "            continue\n",
    "        print(f\"Query embedding done ({embed_time:.2f}s)\")\n",
    "\n",
    "        # 2. Milvus 검색\n",
    "\n",
    "        # 2. Milvus 검색 (수정됨: 함수 호출 방식 변경)\n",
    "        print(f\"Searching Milvus collections {COLLECTION_NAMES} for top {SEARCH_TOP_K} relevant chunks overall...\")\n",
    "        start_search_time = time.time()\n",
    "        # 수정된 함수 호출: 컬렉션 이름 리스트와 최종 원하는 결과 개수 전달\n",
    "        retrieved_data = search_milvus(query_embedding, COLLECTION_NAMES, SEARCH_TOP_K)\n",
    "        search_time = time.time() - start_search_time\n",
    "\n",
    "        if not retrieved_data:\n",
    "            print(\"Milvus에서 관련 정보를 찾지 못했습니다.\")\n",
    "            context_for_llm = \"\"\n",
    "        else:\n",
    "            # 이제 retrieved_data는 여러 컬렉션의 결과를 포함하고 score 기준으로 정렬됨\n",
    "            print(f\"Found {len(retrieved_data)} relevant chunks overall ({search_time:.2f}s).\")\n",
    "            # (선택적) 검색 결과 미리보기 (출처 컬렉션 포함)\n",
    "            # for i, chunk in enumerate(retrieved_data):\n",
    "            #     print(f\"  Result {i+1}: Score={chunk['score']:.4f}, Collection='{chunk['collection']}', Text={chunk['text'][:80]}...\")\n",
    "            context_for_llm = format_context(retrieved_data) # format_context 함수는 그대로 사용 가능\n",
    "\n",
    "        # 3. LLM에게 질문/답변 생성\n",
    "        print(\"Asking LLM...\")\n",
    "        start_llm_time = time.time()\n",
    "        answer = ask_llm(user_query, context_for_llm)\n",
    "        llm_time = time.time() - start_llm_time\n",
    "        print(f\"LLM response received ({llm_time:.2f}s).\")\n",
    "\n",
    "        # 4. 답변 출력\n",
    "        print(\"\\n[답변]\")\n",
    "        print(answer)\n",
    "\n",
    "    print(\"RAG 시스템을 종료합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='### 셀트리온 최근 1년간 재무 성과 및 주요 바이오시밀러 매출 동향 보고서\\n\\n#### 1. 재무 성과 개요\\n\\n셀트리온은 2022년과 2023년 동안 지속적인 성장을 보여주었습니다. 2023년 3분기 발표된 재무 보고서에 따르면, 전년 동기 대비 매출과 순이익이 증가하였습니다. 구체적인 수치는 아직 공개되지 않았지만, 일반적으로 바이오시밀러 시장의 성장과 함께 셀트리온의 매출이 호조를 보였습니다.\\n\\n- **매출 성장**: 셀트리온의 바이오시밀러 제품군에서 매출 증가가 두드러지며, 특히 유럽과 아시아 지역에서의 판매가 크게 증가했습니다.\\n- **순이익**: 운영 효율성을 통해 경상이익이 증가하는 추세를 보였습니다. 연구 개발(R&D) 투자에도 불구하고 마진이 개선되었습니다.\\n\\n#### 2. 주요 바이오시밀러 매출 동향\\n\\n셀트리온의 주력 바이오시밀러 제품군에는 다음과 같은 약물이 포함됩니다:\\n\\n- **트룩시마(Truxima)**: 리툭시맙의 바이오시밀러로, hematologic malignancies 및 자가면역 질환 치료에 사용됩니다. 유럽, 대한민국에서의 시장 점유율 증가로 매출이 상승하였습니다.\\n- **허쥬마(Herceptin)**: 트라스투주맙의 바이오시밀러로, 유방암 및 위암 치료에 사용됩니다. 글로벌 승인 확대와 판매 네트워크 강화로 매출이 증가했습니다.\\n- **유플루자(Infliximab)**: 인플릭시맵의 바이오시밀러로, 자가면역 질환에 대한 수요 증가로 매출이 상승했습니다.\\n\\n이에 따라, 셀트리온은 바이오시밀러 시장에서의 경쟁력을 지속적으로 확보하고 있습니다.\\n\\n#### 3. 신규 개발 현황 요약\\n\\n셀트리온은 끊임없는 연구 개발을 통해 신규 바이오 의약품 및 치료제를 개발 중입니다. 최근 몇 가지 주요 개발 사항은 다음과 같습니다:\\n\\n- **면역항암제 개발**: 셀트리온은 면역항암제의 개발을 확대하고 있으며, 여러 임상시험 단계에 있는 후보물질이 있습니다.\\n- **신규 바이오시밀러 제품**: 기존 제품의 바이오시밀러뿐만 아니라, 새로운 진단 및 치료제에 대한 연구도 활발히 진행 중입니다.\\n- **글로벌 파트너십**: 다양한 글로벌 제약사와의 협력을 통해 파이프라인을 강화하고 있습니다.\\n\\n#### 4. 사업 전략 및 향후 목표\\n\\n셀트리온의 사업 전략은 다음과 같은 방향으로 설정되고 있습니다:\\n\\n- **글로벌 시장 확장**: 유럽, 미국 등 주요 시장에서의 점유율 확대를 목표로 하며, 신규 바이오시밀러 출시를 통해 판매 성장을 꿰할 계획입니다.\\n- **R&D 투자 확대**: 새로운 바이오 의약품 및 치료제 개발에 대한 연구 개발을 지속적으로 확대하여, 혁신적 솔루션을 시장에 출시할 예정입니다.\\n- **지속 가능한 기업 운영**: 환경, 사회적 책임을 고려한 지속 가능한 비즈니스 모델을 구축하고, 사회적 가치를 창출하는 데에도 집중하고 있습니다.\\n\\n이와 같은 전략적 방향성을 바탕으로 셀트리온은 경쟁이 치열한 바이오 의약품 시장에서 입지를 더욱 강화할 것입니다. 또한, 앞으로의 성장은 지속적인 혁신과 글로벌 협력에 기반할 것입니다.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API 키를 환경 변수에서 가져옴\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"오류: OPENAI_API_KEY 환경 변수를 설정해주세요.\")\n",
    "    exit()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  store=True,\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": \"셀트리온의 최근 1년간 재무 성과와 주요 바이오시밀러 매출 동향 보고서 작성해줘. 특히 컨텍스트 정보를 바탕으로 셀트리온의 신규 개발 현황 요약을 포함해줘. 그리고 셀트리온의 사업 전략과 향후 목표에 대한 설명도 포함해줘. \"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
