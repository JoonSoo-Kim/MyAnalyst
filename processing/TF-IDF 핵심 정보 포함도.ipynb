{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from konlpy) (1.5.2)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from konlpy) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from konlpy) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kjsoo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install konlpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_A_1 = \"\"\"\n",
    "4Q24 Review: 매출액 컨센서스 부합, 영업이익은 하회 \n",
    "동사는 4Q24 연결기준 매출액 1조 636억원(YoY+178.0%, QoQ+20.6%), 영업이익 \n",
    "1,964억원(QoQ-5.4%, OPM 18.5%)을 기록, 컨센서스 매출액(1조 493억원)에 부합, \n",
    "영업이익(2,349억원)은 하회하는 실적을 거두었다. 매출원가에 반영된 일회성 요인 \n",
    "(CDMO 생산에 따른 PCO 증가, 3공장 초기 가동 제반비용 등)으로 원가율 목표치를 \n",
    "달성하지는 못했으며(48.9%, QoQ+1.4%p), 4분기에 집중적으로 반영된 프랑스 정부向 \n",
    "비용 등 판관비 단에서도 일회성 요인들이 발생하며 OPM의 하락으로 이어졌다. \n",
    "24년 review: 짐펜트라 미스를 유럽에서 만회   \n",
    "24년에는 동사의 기존 제품군 중 램시마IV(조정매출기준 YoY+28%) 및 트룩시마 \n",
    "(+67%)의 성장이 돋보였으며 신규 제품군 중에서는 베그젤마(+342%)가 큰 폭으로 \n",
    "성장했다. 상기 제품은 주로 항암 제품군이라는 점 이외에도, 24년 유럽 시장에서의 \n",
    "점유율 상승이 특히 돋보였다는 공통점을 갖는다. 동사는 항암 시장에서 동사의 공급 \n",
    "안정성이 경쟁력을 갖는 것으로 언급한 바 있는데, 이 역시 입찰 중심의 유럽 시장에 \n",
    "주로 해당되는 설명으로 판단된다.  \n",
    "한편, 짐펜트라 매출은 4분기 280억, 연간 366억을 달성하며 기대치보다 더딘 출시 \n",
    "첫 해를 기록했다. 짐펜트라의 성공을 위해서는 1)격변하는 PBM 주관 시장에 맞춘 \n",
    "빠른 대응, 2)IBD 적응증 내 글로벌 신약 대비 경쟁력 확보 및 3)마케팅 측면에서의 \n",
    "상대적인 약점 극복이 필요한 것으로 사료된다.  \n",
    "25년 Outlook: 더욱 다채로워지는 포트폴리오+ 신규품목 미국 성장 중요    \n",
    "합병 이후 동사의 투자포인트는 1)구조 효율화를 통한 매출원가율 하락과 수익성 개선, \n",
    "2)짐펜트라 등 차별화된 제품의 성공 및 3)안정적인 사업을 기반으로 신약/CDMO 등 \n",
    "신사업 진출이다. 이 중 IBD 시장의 경쟁 현황, 초기 단계의 신약 파이프라인, 관세 \n",
    "정책 불확실성 및 신규 CDMO 법인의 매출발생 시기 등을 고려했을 때 결국 \n",
    "25년도의 수익성이 단기적으로 기업가치의 driver로 작용할 전망이다. \n",
    "올해는 점유율 상승 여력이 큰 램시마SC의 유럽 매출 및 유플라이마, 베그젤마 등 \n",
    "신규 제품군의 미국 내 성장이 주목할 포인트로 판단된다. 유럽에서 신규 출시되는 \n",
    "4건 이상의 제품은 추가적인 동력을 제공할 전망이다. 이를 반영하여 신규 제품군의 \n",
    "비율이 약 49%를 이룰 것으로 추정(24년도 38.3%), 해당 제품군의 높은 마진율은 \n",
    "동사의 수익성에 기여가 가능하다. 동사의 4Q25 목표 원가율(20% 후반)을 bull case, \n",
    "30%초반을 base case, 30%중반을 bear case로 가정, base case를 적용하여 연간 \n",
    "매출액은 4조 2,631억원(YoY+19.8%), 영업이익 1조 3,515억원(OPM 31.7%)으로 \n",
    "추정한다. 이는 동사의 각 품목 연간 목표치 대비 보수적인 추정을 반영한 값이며, \n",
    "bear case를 적용해도 EPS 성장으로 보정한 동사의 벨류에이션은 섹터 내 대형주 \n",
    "중에서 가장 매력적인 수준이다.  \n",
    "투자의견 Buy 유지, 목표주가 250,000원으로 소폭 하향      \n",
    "동사에 대해 투자의견 Buy, 목표주가를 250,000원으로 소폭 하향한다. 4분기 실적을 \n",
    "반영하여 목표주가 산출의 근거가 된 ‘26년 추정 EBITDA를 2조 1,174억원으로 소폭 \n",
    "하향(기존 2조 3,613억원)하였으며 할인기간을 조정하였다. 짐펜트라에 집중된 동사 \n",
    "실적의 불확실성으로 주가는 박스권을 형성하였으나 향후 이익 성장에 대한 보수적인 \n",
    "추정을 반영해도 상승 여력은 충분한 것으로 판단된다. \n",
    "\"\"\"\n",
    "\n",
    "report_A_2 = \"\"\"\n",
    "4Q24 Review: 일회성 요인으로 영업이익 컨센 하회  \n",
    "셀트리온의 24년 4분기 매출액은 1조 636억원(+178%YoY, +20.6%QoQ), 영\n",
    "업이익은 1,964억원(+967.4%YoY, -5.4%QoQ, OPM 18.5%)으로 컨센서스 매\n",
    "출액 1조 493억원에 부합, 컨센서스 영업이익 2,349억원 대비 16.4% 하회하는 실\n",
    "적을 발표했다.  \n",
    "견조한 매출 성장에도 불구하고 1)3공장 상업 생산 개시(24년 12월)에 따른 초기 운\n",
    "영비의 증가, 2)규제기관 공장 감사에 따른 일회성 비용 발생, 3)신제품 매출 확대를 위\n",
    "한 해외 판관비 증가 및 4)3공장과 해외 인력 채용에 따른 인건비 증가 등 4분기 원\n",
    "가(5,200억원, +24.2%QoQ) 및 판관비(3,470억원, +35.7% QoQ)의 증가로 아\n",
    "쉬운 실적을 기록했다. 시장에서 주목하고 있는 짐펜트라 매출은 280억원\n",
    "(+338%QoQ)을 기록, 다소 아쉬운 상황이나 유플라이마(1,082억원, \n",
    "+157.6%YoY, +14.6%QoQ), 베그젤마(770억원, +413.3%YoY, +11.3%QoQ)\n",
    "등 신규 포트폴리오의 고성장 및 CMO 매출(1,060억원)이 매출 성장을 견인했다.  \n",
    " \n",
    "25년 수익성 개선의 원년, 영업이익 170% 성장 기대  \n",
    "셀트리온의 25년 매출액은 4조 4,192억원(+24.2%YoY), 영업이익은 1조 3,291억\n",
    "원(+170.1%YoY, OPM 30.1%)으로 전망한다.  \n",
    "1)25년에도 유플라이마(5,916억원, +69%YoY), 베그젤마(3,552억원, +61%YoY), \n",
    "스테키마(1,505억원, +653% YoY), 짐펜트라(2,541억원, +594%YoY) 등 고마진 \n",
    "신규 포트폴리오의 고성장이 기대되는 가운데 2)미국내 시밀러 시장 개화에 따른 경쟁\n",
    "심화 우려에도 불구 셀트리온의 미국 매출 비중은 지속적으로 증가하고 있으며 3)24\n",
    "년 합병에 따른 PPA 상각비의 기저효과로 원가율 개선(-12%p YoY)이 가능하다는 \n",
    "점에 긍정적인 주가 흐름을 예상, 투자의견 매수를 유지한다. 다만 25년 추정 \n",
    "EBITDA를 기존 1조 6,730억원에서 1조 6,030억원으로 하향 조정함에 따라 목표\n",
    "주가는 25만원에서 23만원으로 하향한다. \n",
    "\"\"\"\n",
    "\n",
    "report_A_3 = \"\"\"\n",
    "투자의견 매수, 목표주가 240,000원 유지 \n",
    "25년 다수의 바이오시밀러 신제품 출시가 예정되어 있으며, 원가율 하락 및 PPA \n",
    "상각비 기저효과에 따른 이익 개선 본격화 전망. 또한 합병 효과로 유럽 시장 성장\n",
    "이 견조하고, 짐펜트라를 포함한 신제품의 미국향 매출 상승이 기대되어, 동사에 \n",
    "대한 투자의견 매수, 목표주가 240,000원 유지 \n",
    "목표주가는 SOTP 방식으로 산출. 영업가치는 합병 후 원가율 정상화 및 미국 출\n",
    "시 신제품 매출 비중이 높아진 26년 EBITDA를 할인하고, 19년 램시마SC 유럽 출\n",
    "시 당시 Fwd 12m EV/EBITDA를 22% 할인한 26배 적용하여 49.3조원 추정. 순\n",
    "차입금을 반영하여 총 기업가치 49.3조원으로 산정 \n",
    " \n",
    "4Q24 Review: 3공장 초기 가동에 따른 일회성 비용으로 컨센서스 하회 \n",
    "[연결] 매출 1조 636억원(+20.6% QoQ), 영업이익 1,964억원(-5.4% QoQ), OPM \n",
    "18.5% 기록. 매출액은 후속 제품 매출 성장 및 TEVA 향 CMO 매출 약 1,064억\n",
    "원이 반영되어 컨센서스 부합. 영업이익은 3공장 가동 초기 운영에 따른 일회성 \n",
    "비용 반영으로 컨센서스 하회, 다만 25년부터는 해당 비용은 자산으로 반영 예정 \n",
    "[기존 제품] 매출 4,702억원(+0.6% QoQ)로 여전히 유럽 시장에서 안정적인 성장\n",
    "세 유지. [후속 제품] 매출 4,030억원(+17.7% QoQ)로 유플라이마 944억원\n",
    "(+18.0% QoQ), 짐펜트라 64억원(+190.9% QoQ), 스테키마 16억원(+%QoQ) 달\n",
    "성. 유플라이마는 미국에서 3분기 5-60억원대비 4분기 250억원 매출 발생. 이는 \n",
    "Low WAC 제품 출시에 따른 가격 정책 다변화 효과로 판단. 짐펜트라는 PBM 등\n",
    "재 후 도매상 계약이 지속되면서 초기 발주량 증가로 양호한 실적 기록  \n",
    " \n",
    "25년 전망: 유럽과 미국 동반 성장으로 영업이익 1.5조원 달성 기대 \n",
    "25년 매출 4조 8,829억원(+37.3% YoY), 영업이익 1조 5,117억원(+207.3% \n",
    "YoY), OPM 31.0%로 본격적인 이익 확대 구간에 진입할 것으로 전망 \n",
    "24년 짐펜트라 연간 매출 373억원으로 아쉬운 실적을 기록하였으나, 미국 내 영\n",
    "업 조직 안정화 및 PBM 연계 보험사 Formulary 등재 확대되며, 처방량 및 제품 \n",
    "출하량 증가 추세. 또한 연내 5개 바이오시밀러 신제품이 유럽 및 미국 시장에 순\n",
    "차적으로 출시되며 매출 확대에 기여할 것으로 기대\n",
    "\"\"\"\n",
    "\n",
    "report_A_4 =\"\"\"\n",
    "4Q24Re: 비용 증가하며 아쉬운 실적 \n",
    "연결 기준 매출액 1조 636억원(+178.0%YoY, 이하 YoY 생략), 영업이익 1,964억원\n",
    "(+967.4%, OPM 18.5%)로 영업 이익은 컨센서스를 하회. 3공장 상업 생산이 시작되며 관\n",
    "련 인건비, 준비 비용 등 운영 비용 증가와 일부 1회성 비용 등의 영향. 4Q24 제품 원가율\n",
    "은 49% 수준으로 3공장 가동 시작에 따른 영향을 제외할 경우 45% 수준으로 하락. 25년\n",
    "부터는 허쥬마 시밀러의 상각 비용이 반영되지 않으며, 램시마 관련 상각 비용도 25년말부\n",
    "터는 반영되지 않으면서 원가율 개선에 기여할 것으로 전망. 램시마IV, 트룩시마 등 기존 제\n",
    "품들이 견조한 점유율 증가를 이어가는 동시에 램시마SC(유럽), 베그젤마, 유플라이마 등 \n",
    "신규 제품 매출 비중도 커지고 있어 25년 이익율 개선될 것으로 판단. \n",
    "짐펜트라(미국)의 4Q24 매출은 약 280억원 수준으로 아쉬운 매출을 기록. 이는 미국 내에\n",
    "서 동사와 짐펜트라에 대한 낮은 브랜드 인지도 영향 및 미국 내 판매 채널 확대 과정에 있\n",
    "기 때문으로 판단. 24년 말부터 본격적으로 광고를 시작했으며 SC 제형의 높은 편의성 등\n",
    "을 고려할 때 25년에는 개선된 매출 기대. \n",
    "유럽과 다른 미국 시장 \n",
    "25년 최대 5개의 신규 시밀러를 순차적으로 출시할 예정. 다만, 신규 시밀러의 경우에도 유\n",
    "플라이마 시장과 비슷하게 유럽 시장에서는 빠른 시장 침투가 가능할 것으로 판단되나 미국\n",
    "의 경우 초기 시장 진입은 다소 더딜 것으로 판단. 이는 공보험 제도 및 입찰 시장 중심의 \n",
    "유럽과 달리 미국 시장에서는 사보험 중심 영향. \n",
    "투자의견 Buy, 목표주가 24만원으로 하향 \n",
    "매수 의견을 유지하며 목표 주가는 기존 25만원에서 24만원으로 소폭 하향. 목표 주가 하\n",
    "향은 25년 실적 추정치를 하향에 기인. 25년 헬스케어 합병으로 인한 원가율 상승, 상각 비\n",
    "용 반영 등이 완화되며 본격적인 이익 개선 가능할 것으로 전망. \n",
    "\"\"\"\n",
    "\n",
    "report_B = \"\"\"\n",
    "### 제품 관련 소식\n",
    "\n",
    "셀트리온은 현재 9개의 바이오시밀러 제품 포트폴리오를 보유하고 있으며, 최근 '옴리클로', '아이덴젤트', '스테키마'와 같은 신규 제품에 대한 허가를 획득하였습니다. 이 외에도 류마티스 관절염 치료제 '악템라', 골다공증 치료제 '프롤리아', 다발성경화증 치료제 '오크레부스' 등 후속 바이오시밀러 제품의 허가 절차가 진행되고 있습니다. 이러한 제품들은 셀트리온의 글로벌 시장 점유율 확대에 기여할 것으로 기대됩니다.\n",
    "\n",
    "특히, 셀트리온은 자가면역질환 치료 신약 '짐펜트라'의 미국 시장 진출 이후, 처방약급여관리업체(PBM)와의 커버리지를 확대하여 성과를 내고 있으며, 이 제품은 향후 매출 성장의 중요한 동력으로 기대되고 있습니다. 짐펜트라는 3대 PBM 모두의 처방 목록에 등재되어 있어 시장에서의 입지를 강화하고 있습니다.\n",
    "\n",
    "### R&D 및 파이프라인\n",
    "\n",
    "셀트리온은 연구개발에 연간 매출액의 약 20%를 투자하고 있으며, 바이오시밀러 파이프라인 확대와 항체의약품 신약 개발을 지속적으로 추진하고 있습니다. 최근에는 CT-P47 (악템라 바이오시밀러)의 글로벌 임상 3상 결과에서 오리지널 의약품 대비 동등성 및 유사성을 확인하였으며, 이 결과를 바탕으로 해외 주요 국가에서 허가 신청을 가속화할 계획입니다. 또한, CT-P51 (키트루다 바이오시밀러)의 유럽 임상 3상 시험계획이 동시 승인됨에 따라, 향후 시장 진출 기대가 높아지고 있습니다.\n",
    "\n",
    "### CMO 사업\n",
    "\n",
    "셀트리온은 기존의 CMO 사업을 한층 강화하기 위해 새로운 의약품 위탁개발생산(CDMO) 자회사를 설립하였습니다. 이 자회사는 신약 후보물질 선별부터 상업 생산까지 전 주기 서비스를 제공할 예정이며, 셀트리온의 항체 개발 및 생산 노하우를 활용하여 경쟁력을 높일 계획입니다. 이는 셀트리온의 CDMO 사업 진출을 본격화하는 중요한 단계로, 향후 글로벌 바이오의약품 수요 확대에 대응할 수 있는 기반을 마련할 것입니다.\n",
    "\n",
    "### 기타 사업\n",
    "\n",
    "셀트리온은 최근 3개국(한국, 홍콩, 대만)에서 OTC(일반의약품) 영업 양도 계약을 체결한 바 있습니다. 이를 통해 핵심사업에 집중하고 사업 구조를 재편하여 기업 가치를 제고하는 목표를 가지고 있습니다. 이와 같은 전략은 셀트리온의 재무구조 개선에도 긍정적인 영향을 미칠 것으로 기대됩니다.\n",
    "\n",
    "이와 같은 주요 사업 및 제품 동향은 셀트리온의 지속적인 성장과 글로벌 시장에서의 경쟁력 강화를 위한 중요한 요소로 작용하고 있습니다.\n",
    "\n",
    "### 4. 시장 환경 및 전략 방향 (Market Environment & Strategy)\n",
    "\n",
    "### 주요 시장 활동\n",
    "\n",
    "셀트리온은 2024년 4분기 동안 주요 시장인 미국과 유럽에서 활발한 활동을 전개하고 있습니다. 특히, 독일 시장에서 램시마 제품군(IV∙SC)의 점유율이 71%에 달하며, 이는 셀트리온의 제품 경쟁력을 강화하는 데 중요한 역할을 하고 있습니다. 스테키마의 출시를 통해 셀트리온은 항체 바이오 의약품 분야에서의 입지를 더욱 확고히 하고 있으며, 자가면역질환 포트폴리오를 확장하여 의료진과 환자 선택권을 높이고 있습니다.\n",
    "\n",
    "또한, 호주 시장에서도 램시마SC의 판매가 증가하고 있으며, 현지 법인이 주요 이해관계자와의 네트워크를 강화하고 임상 데이터를 알리면서 처방 선호도를 높이고 있습니다. 이러한 현지화 전략은 셀트리온의 글로벌 시장 점유율 확대에 긍정적인 영향을 미치고 있습니다.\n",
    "\n",
    "### 회사의 공식 전략\n",
    "\n",
    "셀트리온은 2024년 12월에 유럽 30개국에서의 판매 승인 권고를 획득한 바이오시밀러 제품을 통해 글로벌 시장에서의 경쟁력을 강화하고 있습니다. 회사는 2030년까지 22개 제품 라인업 구축을 목표로 하며, 바이오시밀러 시장의 높은 성장세를 활용하여 지속적으로 시장 점유율을 확대할 계획입니다.\n",
    "\n",
    "셀트리온은 CDMO(의약품 위탁개발생산) 사업 진출을 통해 신규 수익원을 창출하고, 의약품 개발 전주기 서비스를 제공하는 신규 자회사를 설립하였습니다. 이 자회사는 신약 후보물질 선별부터 상업 생산까지 모든 단계를 지원하며, 경쟁력 있는 생산성과 원가 절감에 중점을 두고 운영될 것입니다.\n",
    "\n",
    "또한, 셀트리온은 베트남 시장에 진출하여 유플라이마, 베그젤마, 옴리클로 등의 바이오시밀러 제품을 출시할 예정이며, 현지 네트워크 구축과 영업 활동을 통해 시장 점유율을 높이는 전략을 추진하고 있습니다.\n",
    "\n",
    "이와 같은 전략적 방향은 셀트리온이 글로벌 바이오의약품 시장에서 지속 가능한 성장을 이루는 데 중요한 요소로 작용할 것입니다.\n",
    "\n",
    "### 5. 향후 전망 (공식 발표 기반)\n",
    "\n",
    "셀트리온은 향후 2025년 사업 계획과 목표에 대해 구체적인 비전을 제시하고 있습니다. 회사는 2025년까지 바이오시밀러 사업 부문에서 11개 제품의 허가를 획득하고, 2030년까지 22개 제품의 포트폴리오를 확립하여 시장 지배력을 강화할 계획입니다. 이는 자가면역질환 치료제뿐만 아니라 천식, 두드러기, 안과, 대사성 골질환 등 다양한 치료 영역으로의 확장을 포함합니다. 이를 통해 다제품 전략을 통해 처방약급여관리업체(PBM)와의 협상력을 강화하고 판매 효율성을 높이겠다는 전략을 세우고 있습니다.\n",
    "\n",
    "서정진 회장은 자가면역질환 치료제 ‘짐펜트라’가 미국 시장에서 점유율을 확대하고 있으며, 내년에는 매출 5조원 달성을 목표로 하고 있다고 밝혔습니다. 올해 목표 매출인 2500억원은 충분히 달성 가능할 것으로 전망하고 있으며, 다른 바이오시밀러 제품들도 주요 시장에서 점유율을 꾸준히 확대하고 있다는 자신감을 드러냈습니다.\n",
    "\n",
    "또한, 셀트리온은 CDMO(위탁개발생산) 사업을 본격적으로 추진하고 있으며, 연내 자회사를 설립하여 CDMO 사업의 경쟁력을 높이는 데 집중할 계획입니다. 이 사업은 2028년부터 매출이 발생할 것으로 예상하고 있으며, 항체, 이중항체, 펩타이드 등 다양한 서비스를 제공하여 글로벌 시장에서의 입지를 강화하겠다는 목표를 가지고 있습니다.\n",
    "\n",
    "이와 함께 셀트리온은 신규 제조소 확보와 관련하여 결정은 연내 마무리 짓겠다고 밝혔으며, 이를 통해 글로벌 톱티어급 생산 능력을 구축하고 의약품 공급 사이클의 모든 단계에서 고객의 요구에 맞춤형 서비스를 제공할 수 있을 것으로 기대하고 있습니다.\n",
    "\n",
    "향후 실적에 영향을 미칠 수 있는 주요 요인으로는 신제품 성과, 진행 중인 R&D의 중요성, 시장 환경의 변화 등을 포함할 수 있으며, 회사의 지속적인 성장과 발전을 위한 노력은 기업의 가치를 높이는 데 기여할 것으로 전망됩니다.\n",
    "\n",
    "### 6. 기타 참고사항\n",
    "\n",
    "1. 리스크 요인:\n",
    "    - 셀트리온의 사업 전략 및 성과는 글로벌 시장의 경쟁 환경, 규제 변화, 그리고 경제적 요인에 따라 영향을 받을 수 있습니다. 특히, 바이오시밀러 제품의 경우, 경쟁사가 출시하는 유사 제품의 개발 속도와 시장 반응이 중요한 변수로 작용할 수 있습니다.\n",
    "    - 또한, 임상시험 및 제품 허가 과정에서 발생할 수 있는 지연이나 실패는 재무적 측면에서 부정적인 영향을 미칠 수 있습니다.\n",
    "2. 기회 요인:\n",
    "    - 셀트리온은 바이오시밀러와 신약 개발 부문에서 지속적인 연구개발 투자로 새로운 치료 옵션을 제공할 수 있는 기회를 갖고 있습니다. 특히, 다중항체 플랫폼 기술 개발과 같은 혁신적인 접근 방식은 향후 시장에서의 경쟁력을 강화할 가능성이 있습니다.\n",
    "    - 글로벌 시장에서의 판매 확대 및 파트너십 체결을 통해 매출 성장을 도모할 수 있는 잠재적인 기회가 존재합니다.\n",
    "3. 전략적 제휴 및 파트너십:\n",
    "    - 셀트리온은 여러 글로벌 제약사와의 협력 및 라이선스 계약을 통해 개발 비용을 분담하고 새로운 시장에 진입할 수 있는 기회를 모색하고 있습니다.\n",
    "    - 이러한 전략적 제휴는 기술력 향상과 시장 점유율 확대에 기여할 수 있습니다.\n",
    "4. 주주 가치 제고:\n",
    "    - 셀트리온은 2024년 내 자기주식 매입을 검토 중이며, 이를 통해 주주 가치를 증대시킬 계획을 세우고 있습니다.\n",
    "5. 기타 중요 사항:\n",
    "    - 셀트리온의 연구개발 투자 비율은 매출액의 약 20%에 달하며, 이는 바이오시밀러 및 신약 개발에 대한 의지를 반영합니다.\n",
    "    - 회사는 향후 중장기적인 사업 계획 및 경영 전략을 지속적으로 업데이트할 예정이며, 이는 투자자들에게 중요한 정보로 작용할 수 있습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 계산 중 (전체 문서 대상)...\n",
      "TF-IDF 계산 완료. 총 1013개의 고유 단어 발견.\n",
      "\n",
      "--- 후보 보고서 (report_B) TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- 개별 참조 보고서와의 TF-IDF Top 50 포함도 평가 ---\n",
      "\n",
      "=== 비교: report_B vs report_A_1 ===\n",
      "--- report_A_1 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 3\n",
      "\n",
      "[결과 for report_A_1]\n",
      "Recall (재현율): 0.0600\n",
      "Precision (정밀도): 0.0600\n",
      "F1-Score: 0.0600\n",
      "------------------------------\n",
      "\n",
      "=== 비교: report_B vs report_A_2 ===\n",
      "--- report_A_2 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 1\n",
      "\n",
      "[결과 for report_A_2]\n",
      "Recall (재현율): 0.0200\n",
      "Precision (정밀도): 0.0200\n",
      "F1-Score: 0.0200\n",
      "------------------------------\n",
      "\n",
      "=== 비교: report_B vs report_A_3 ===\n",
      "--- report_A_3 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 4\n",
      "\n",
      "[결과 for report_A_3]\n",
      "Recall (재현율): 0.0800\n",
      "Precision (정밀도): 0.0800\n",
      "F1-Score: 0.0800\n",
      "------------------------------\n",
      "\n",
      "=== 비교: report_B vs report_A_4 ===\n",
      "--- report_A_4 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 3\n",
      "\n",
      "[결과 for report_A_4]\n",
      "Recall (재현율): 0.0600\n",
      "Precision (정밀도): 0.0600\n",
      "F1-Score: 0.0600\n",
      "------------------------------\n",
      "\n",
      "==================================================\n",
      "--- 최종 평균 점수 (TF-IDF Top 50 기반) ---\n",
      "* 비교 대상 후보(B): report_B\n",
      "* 비교 기준 참조(A): report_A_1, report_A_2, report_A_3, report_A_4 (4개)\n",
      "\n",
      "Average Recall:    0.0550\n",
      "Average Precision: 0.0550\n",
      "Average F1-Score:  0.0550\n",
      "==================================================\n",
      "\n",
      "--- 중요 참고사항 ---\n",
      "1. 이 평가는 각 보고서에서 TF-IDF 점수가 높은 **상위 50개 단어**를 '핵심 정보'로 간주하고 그 **겹침**을 비교한 결과입니다.\n",
      "2. **`top_n` 값**을 어떻게 설정하느냐에 따라 결과가 크게 달라질 수 있습니다.\n",
      "3. TF-IDF는 단어의 **통계적 중요도**를 반영하지만, **문맥, 의미적 유사성, 동의어** 등은 고려하지 못합니다.\n",
      "4. 특히 한국어의 경우, **형태소 분석이나 불용어 처리**를 하지 않은 기본 TF-IDF는 조사, 어미 등 중요도가 낮은 단어가 높게 평가될 수 있어 결과 해석에 유의해야 합니다.\n",
      "5. 이 방법은 앞서 제시된 '명사 기반' 접근법과는 다른 관점(단어의 통계적 중요도)을 제공하며, 상호 보완적으로 결과를 해석하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np # numpy 배열 연산을 위해 필요\n",
    "\n",
    "# --- 1. 보고서 목록 및 이름 정의 ---\n",
    "candidate_report = report_B\n",
    "reference_reports = [report_A_1, report_A_2, report_A_3, report_A_4]\n",
    "\n",
    "# TF-IDF 계산을 위해 모든 문서를 하나의 리스트로 합칩니다.\n",
    "# 순서: 참조 보고서들 -> 후보 보고서\n",
    "all_documents = reference_reports + [candidate_report]\n",
    "\n",
    "# 각 문서의 이름을 저장합니다 (TF-IDF 매트릭스 인덱스와 순서 일치 중요).\n",
    "reference_names = [\"report_A_1\", \"report_A_2\", \"report_A_3\", \"report_A_4\"]\n",
    "candidate_name = \"report_B\"\n",
    "all_doc_names = reference_names + [candidate_name]\n",
    "\n",
    "# 후보 보고서(B)가 all_documents 리스트에서 몇 번째 인덱스인지 확인합니다 (마지막).\n",
    "candidate_index = len(all_documents) - 1\n",
    "\n",
    "# --- 2. TF-IDF 계산 ---\n",
    "print(\"TF-IDF 계산 중 (전체 문서 대상)...\")\n",
    "# TfidfVectorizer 객체 생성 (한국어 전처리 추가 권장)\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit_transform: 모든 문서 기준 단어 사전 구축 및 TF-IDF 행렬 계산\n",
    "tfidf_matrix = vectorizer.fit_transform(all_documents)\n",
    "\n",
    "# 학습된 단어 목록\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"TF-IDF 계산 완료. 총 {len(feature_names)}개의 고유 단어 발견.\")\n",
    "\n",
    "# 결과를 보기 쉽게 DataFrame으로도 만들어 둡니다 (선택 사항, 주석 처리됨)\n",
    "# tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=all_doc_names, columns=feature_names)\n",
    "# print(\"--- 전체 TF-IDF 계산 결과 (DataFrame) ---\")\n",
    "# print(tfidf_df)\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# --- 3. TF-IDF 기반 핵심 정보(상위 N개 단어) 추출 함수 및 설정 ---\n",
    "\n",
    "# 각 보고서에서 TF-IDF 점수가 높은 상위 몇 개의 단어를 핵심 정보로 간주할지 설정\n",
    "top_n = 50 # 예시: 상위 100개 단어 사용 (필요에 따라 조절)\n",
    "\n",
    "def get_top_n_tfidf_terms(doc_index, tfidf_matrix, feature_names, top_n):\n",
    "    \"\"\"\n",
    "    주어진 문서 인덱스에 해당하는 TF-IDF 벡터에서 점수가 높은 상위 N개 단어 집합 반환.\n",
    "    \"\"\"\n",
    "    # 해당 문서의 TF-IDF 벡터 추출 (1차원 배열로 변환)\n",
    "    tfidf_vector = tfidf_matrix[doc_index].toarray().flatten()\n",
    "\n",
    "    # TF-IDF 점수 내림차순 정렬 시 원본 인덱스 가져오기\n",
    "    sorted_indices = np.argsort(tfidf_vector)[::-1]\n",
    "\n",
    "    # 상위 N개 인덱스 선택 (점수가 0보다 큰 경우만)\n",
    "    top_indices = [idx for idx in sorted_indices[:top_n] if tfidf_vector[idx] > 0]\n",
    "\n",
    "    # 해당 인덱스의 단어들을 집합(Set)으로 반환\n",
    "    top_terms = {feature_names[i] for i in top_indices}\n",
    "    return top_terms\n",
    "\n",
    "# --- 4. 후보 보고서(B)의 상위 N개 TF-IDF 단어 추출 (한 번만 수행) ---\n",
    "key_terms_B_tfidf = get_top_n_tfidf_terms(candidate_index, tfidf_matrix, feature_names, top_n)\n",
    "print(f\"\\n--- 후보 보고서 ({candidate_name}) TF-IDF Top {top_n} 단어 (총 {len(key_terms_B_tfidf)}개) ---\")\n",
    "# print(f\"{sorted(list(key_terms_B_tfidf))}\") # 필요시 단어 목록 출력 주석 해제\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# --- 5. 각 참조 보고서(A)와 비교 및 점수 계산 ---\n",
    "all_recalls_tfidf = []\n",
    "all_precisions_tfidf = []\n",
    "all_f1_scores_tfidf = []\n",
    "\n",
    "print(f\"--- 개별 참조 보고서와의 TF-IDF Top {top_n} 포함도 평가 ---\")\n",
    "# 참조 보고서들의 인덱스 (0부터 candidate_index - 1 까지) 순회\n",
    "for i in range(len(reference_reports)):\n",
    "    ref_name = all_doc_names[i]\n",
    "    print(f\"\\n=== 비교: {candidate_name} vs {ref_name} ===\")\n",
    "\n",
    "    # 현재 참조 보고서(A_i)의 상위 N개 TF-IDF 단어 추출\n",
    "    key_terms_A_tfidf = get_top_n_tfidf_terms(i, tfidf_matrix, feature_names, top_n)\n",
    "    print(f\"--- {ref_name} TF-IDF Top {top_n} 단어 (총 {len(key_terms_A_tfidf)}개) ---\")\n",
    "    # print(f\"{sorted(list(key_terms_A_tfidf))}\") # 필요시 단어 목록 출력 주석 해제\n",
    "\n",
    "    # 교집합: 두 보고서 모두에서 상위 N개 핵심 단어에 포함된 단어들\n",
    "    common_terms_tfidf = key_terms_A_tfidf.intersection(key_terms_B_tfidf)\n",
    "    print(f\"\\n* 공통 Top {top_n} 단어 수: {len(common_terms_tfidf)}\")\n",
    "    # if len(common_terms_tfidf) > 0: # 필요시 공통 단어 목록 출력 주석 해제\n",
    "    #     print(f\"  - 공통 단어 목록: {sorted(list(common_terms_tfidf))}\")\n",
    "\n",
    "    # Recall 계산: A의 Top N 중 B의 Top N에도 포함된 비율\n",
    "    if len(key_terms_A_tfidf) == 0:\n",
    "        recall_tfidf = 0.0\n",
    "    else:\n",
    "        recall_tfidf = len(common_terms_tfidf) / len(key_terms_A_tfidf)\n",
    "\n",
    "    # Precision 계산: B의 Top N 중 A의 Top N에도 포함된 비율\n",
    "    if len(key_terms_B_tfidf) == 0:\n",
    "        precision_tfidf = 0.0\n",
    "    else:\n",
    "        precision_tfidf = len(common_terms_tfidf) / len(key_terms_B_tfidf)\n",
    "\n",
    "    # F1-Score 계산\n",
    "    if (recall_tfidf + precision_tfidf) == 0:\n",
    "        f1_score_tfidf = 0.0\n",
    "    else:\n",
    "        f1_score_tfidf = 2 * (recall_tfidf * precision_tfidf) / (recall_tfidf + precision_tfidf)\n",
    "\n",
    "    # 결과 저장 및 개별 출력\n",
    "    all_recalls_tfidf.append(recall_tfidf)\n",
    "    all_precisions_tfidf.append(precision_tfidf)\n",
    "    all_f1_scores_tfidf.append(f1_score_tfidf)\n",
    "\n",
    "    print(f\"\\n[결과 for {ref_name}]\")\n",
    "    print(f\"Recall (재현율): {recall_tfidf:.4f}\")\n",
    "    print(f\"Precision (정밀도): {precision_tfidf:.4f}\")\n",
    "    print(f\"F1-Score: {f1_score_tfidf:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# --- 6. 평균 점수 계산 및 출력 ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"--- 최종 평균 점수 (TF-IDF Top {top_n} 기반) ---\")\n",
    "if len(reference_reports) > 0:\n",
    "    # 평균 계산\n",
    "    avg_recall_tfidf = sum(all_recalls_tfidf) / len(all_recalls_tfidf)\n",
    "    avg_precision_tfidf = sum(all_precisions_tfidf) / len(all_precisions_tfidf)\n",
    "    avg_f1_tfidf = sum(all_f1_scores_tfidf) / len(all_f1_scores_tfidf)\n",
    "\n",
    "    # 사용된 보고서 이름 목록 생성\n",
    "    ref_names_str = ', '.join(reference_names)\n",
    "\n",
    "    print(f\"* 비교 대상 후보(B): {candidate_name}\")\n",
    "    print(f\"* 비교 기준 참조(A): {ref_names_str} ({len(reference_reports)}개)\")\n",
    "    print(f\"\\nAverage Recall:    {avg_recall_tfidf:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision_tfidf:.4f}\")\n",
    "    print(f\"Average F1-Score:  {avg_f1_tfidf:.4f}\")\n",
    "else:\n",
    "    print(\"비교할 참조 보고서가 없습니다.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n--- 중요 참고사항 ---\")\n",
    "print(f\"1. 이 평가는 각 보고서에서 TF-IDF 점수가 높은 **상위 {top_n}개 단어**를 '핵심 정보'로 간주하고 그 **겹침**을 비교한 결과입니다.\")\n",
    "print(f\"2. **`top_n` 값**을 어떻게 설정하느냐에 따라 결과가 크게 달라질 수 있습니다.\")\n",
    "print(\"3. TF-IDF는 단어의 **통계적 중요도**를 반영하지만, **문맥, 의미적 유사성, 동의어** 등은 고려하지 못합니다.\")\n",
    "print(\"4. 특히 한국어의 경우, **형태소 분석이나 불용어 처리**를 하지 않은 기본 TF-IDF는 조사, 어미 등 중요도가 낮은 단어가 높게 평가될 수 있어 결과 해석에 유의해야 합니다.\")\n",
    "print(\"5. 이 방법은 앞서 제시된 '명사 기반' 접근법과는 다른 관점(단어의 통계적 중요도)을 제공하며, 상호 보완적으로 결과를 해석하는 것이 좋습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 계산 중 (전체 문서 대상)...\n",
      "TF-IDF 계산 완료. 총 616개의 고유 단어 발견.\n",
      "\n",
      "--- 후보 보고서 (report_B) TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- 개별 참조 보고서와의 TF-IDF Top 50 포함도 평가 ---\n",
      "\n",
      "=== 비교: report_B vs report_A_1 ===\n",
      "--- report_A_1 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 10\n",
      "\n",
      "[결과 for report_A_1]\n",
      "Recall (재현율): 0.2000\n",
      "Precision (정밀도): 0.2000\n",
      "F1-Score: 0.2000\n",
      "------------------------------\n",
      "\n",
      "=== 비교: report_B vs report_A_2 ===\n",
      "--- report_A_2 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 8\n",
      "\n",
      "[결과 for report_A_2]\n",
      "Recall (재현율): 0.1600\n",
      "Precision (정밀도): 0.1600\n",
      "F1-Score: 0.1600\n",
      "------------------------------\n",
      "\n",
      "=== 비교: report_B vs report_A_3 ===\n",
      "--- report_A_3 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 5\n",
      "\n",
      "[결과 for report_A_3]\n",
      "Recall (재현율): 0.1000\n",
      "Precision (정밀도): 0.1000\n",
      "F1-Score: 0.1000\n",
      "------------------------------\n",
      "\n",
      "==================================================\n",
      "--- 최종 평균 점수 (TF-IDF Top 50 기반) ---\n",
      "* 비교 대상 후보(B): report_B\n",
      "* 비교 기준 참조(A): report_A_1, report_A_2, report_A_3, report_A_4 (3개)\n",
      "\n",
      "Average Recall:    0.1533\n",
      "Average Precision: 0.1533\n",
      "Average F1-Score:  0.1533\n",
      "==================================================\n",
      "\n",
      "--- 중요 참고사항 ---\n",
      "1. 이 평가는 각 보고서에서 TF-IDF 점수가 높은 **상위 50개 단어**를 '핵심 정보'로 간주하고 그 **겹침**을 비교한 결과입니다.\n",
      "2. **`top_n` 값**을 어떻게 설정하느냐에 따라 결과가 크게 달라질 수 있습니다.\n",
      "3. TF-IDF는 단어의 **통계적 중요도**를 반영하지만, **문맥, 의미적 유사성, 동의어** 등은 고려하지 못합니다.\n",
      "4. 특히 한국어의 경우, **형태소 분석이나 불용어 처리**를 하지 않은 기본 TF-IDF는 조사, 어미 등 중요도가 낮은 단어가 높게 평가될 수 있어 결과 해석에 유의해야 합니다.\n",
      "5. 이 방법은 앞서 제시된 '명사 기반' 접근법과는 다른 관점(단어의 통계적 중요도)을 제공하며, 상호 보완적으로 결과를 해석하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np # numpy 배열 연산을 위해 필요\n",
    "\n",
    "# --- 1. 보고서 목록 및 이름 정의 ---\n",
    "candidate_report = report_A_1\n",
    "reference_reports = [report_A_2, report_A_3, report_A_4]\n",
    "\n",
    "# TF-IDF 계산을 위해 모든 문서를 하나의 리스트로 합칩니다.\n",
    "# 순서: 참조 보고서들 -> 후보 보고서\n",
    "all_documents = reference_reports + [candidate_report]\n",
    "\n",
    "# 각 문서의 이름을 저장합니다 (TF-IDF 매트릭스 인덱스와 순서 일치 중요).\n",
    "reference_names = [\"report_A_1\", \"report_A_2\", \"report_A_3\", \"report_A_4\"]\n",
    "candidate_name = \"report_B\"\n",
    "all_doc_names = reference_names + [candidate_name]\n",
    "\n",
    "# 후보 보고서(B)가 all_documents 리스트에서 몇 번째 인덱스인지 확인합니다 (마지막).\n",
    "candidate_index = len(all_documents) - 1\n",
    "\n",
    "# --- 2. TF-IDF 계산 ---\n",
    "print(\"TF-IDF 계산 중 (전체 문서 대상)...\")\n",
    "# TfidfVectorizer 객체 생성 (한국어 전처리 추가 권장)\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit_transform: 모든 문서 기준 단어 사전 구축 및 TF-IDF 행렬 계산\n",
    "tfidf_matrix = vectorizer.fit_transform(all_documents)\n",
    "\n",
    "# 학습된 단어 목록\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"TF-IDF 계산 완료. 총 {len(feature_names)}개의 고유 단어 발견.\")\n",
    "\n",
    "# 결과를 보기 쉽게 DataFrame으로도 만들어 둡니다 (선택 사항, 주석 처리됨)\n",
    "# tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=all_doc_names, columns=feature_names)\n",
    "# print(\"--- 전체 TF-IDF 계산 결과 (DataFrame) ---\")\n",
    "# print(tfidf_df)\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# --- 3. TF-IDF 기반 핵심 정보(상위 N개 단어) 추출 함수 및 설정 ---\n",
    "\n",
    "# 각 보고서에서 TF-IDF 점수가 높은 상위 몇 개의 단어를 핵심 정보로 간주할지 설정\n",
    "top_n = 50 # 예시: 상위 100개 단어 사용 (필요에 따라 조절)\n",
    "\n",
    "def get_top_n_tfidf_terms(doc_index, tfidf_matrix, feature_names, top_n):\n",
    "    \"\"\"\n",
    "    주어진 문서 인덱스에 해당하는 TF-IDF 벡터에서 점수가 높은 상위 N개 단어 집합 반환.\n",
    "    \"\"\"\n",
    "    # 해당 문서의 TF-IDF 벡터 추출 (1차원 배열로 변환)\n",
    "    tfidf_vector = tfidf_matrix[doc_index].toarray().flatten()\n",
    "\n",
    "    # TF-IDF 점수 내림차순 정렬 시 원본 인덱스 가져오기\n",
    "    sorted_indices = np.argsort(tfidf_vector)[::-1]\n",
    "\n",
    "    # 상위 N개 인덱스 선택 (점수가 0보다 큰 경우만)\n",
    "    top_indices = [idx for idx in sorted_indices[:top_n] if tfidf_vector[idx] > 0]\n",
    "\n",
    "    # 해당 인덱스의 단어들을 집합(Set)으로 반환\n",
    "    top_terms = {feature_names[i] for i in top_indices}\n",
    "    return top_terms\n",
    "\n",
    "# --- 4. 후보 보고서(B)의 상위 N개 TF-IDF 단어 추출 (한 번만 수행) ---\n",
    "key_terms_B_tfidf = get_top_n_tfidf_terms(candidate_index, tfidf_matrix, feature_names, top_n)\n",
    "print(f\"\\n--- 후보 보고서 ({candidate_name}) TF-IDF Top {top_n} 단어 (총 {len(key_terms_B_tfidf)}개) ---\")\n",
    "# print(f\"{sorted(list(key_terms_B_tfidf))}\") # 필요시 단어 목록 출력 주석 해제\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# --- 5. 각 참조 보고서(A)와 비교 및 점수 계산 ---\n",
    "all_recalls_tfidf = []\n",
    "all_precisions_tfidf = []\n",
    "all_f1_scores_tfidf = []\n",
    "\n",
    "print(f\"--- 개별 참조 보고서와의 TF-IDF Top {top_n} 포함도 평가 ---\")\n",
    "# 참조 보고서들의 인덱스 (0부터 candidate_index - 1 까지) 순회\n",
    "for i in range(len(reference_reports)):\n",
    "    ref_name = all_doc_names[i]\n",
    "    print(f\"\\n=== 비교: {candidate_name} vs {ref_name} ===\")\n",
    "\n",
    "    # 현재 참조 보고서(A_i)의 상위 N개 TF-IDF 단어 추출\n",
    "    key_terms_A_tfidf = get_top_n_tfidf_terms(i, tfidf_matrix, feature_names, top_n)\n",
    "    print(f\"--- {ref_name} TF-IDF Top {top_n} 단어 (총 {len(key_terms_A_tfidf)}개) ---\")\n",
    "    # print(f\"{sorted(list(key_terms_A_tfidf))}\") # 필요시 단어 목록 출력 주석 해제\n",
    "\n",
    "    # 교집합: 두 보고서 모두에서 상위 N개 핵심 단어에 포함된 단어들\n",
    "    common_terms_tfidf = key_terms_A_tfidf.intersection(key_terms_B_tfidf)\n",
    "    print(f\"\\n* 공통 Top {top_n} 단어 수: {len(common_terms_tfidf)}\")\n",
    "    # if len(common_terms_tfidf) > 0: # 필요시 공통 단어 목록 출력 주석 해제\n",
    "    #     print(f\"  - 공통 단어 목록: {sorted(list(common_terms_tfidf))}\")\n",
    "\n",
    "    # Recall 계산: A의 Top N 중 B의 Top N에도 포함된 비율\n",
    "    if len(key_terms_A_tfidf) == 0:\n",
    "        recall_tfidf = 0.0\n",
    "    else:\n",
    "        recall_tfidf = len(common_terms_tfidf) / len(key_terms_A_tfidf)\n",
    "\n",
    "    # Precision 계산: B의 Top N 중 A의 Top N에도 포함된 비율\n",
    "    if len(key_terms_B_tfidf) == 0:\n",
    "        precision_tfidf = 0.0\n",
    "    else:\n",
    "        precision_tfidf = len(common_terms_tfidf) / len(key_terms_B_tfidf)\n",
    "\n",
    "    # F1-Score 계산\n",
    "    if (recall_tfidf + precision_tfidf) == 0:\n",
    "        f1_score_tfidf = 0.0\n",
    "    else:\n",
    "        f1_score_tfidf = 2 * (recall_tfidf * precision_tfidf) / (recall_tfidf + precision_tfidf)\n",
    "\n",
    "    # 결과 저장 및 개별 출력\n",
    "    all_recalls_tfidf.append(recall_tfidf)\n",
    "    all_precisions_tfidf.append(precision_tfidf)\n",
    "    all_f1_scores_tfidf.append(f1_score_tfidf)\n",
    "\n",
    "    print(f\"\\n[결과 for {ref_name}]\")\n",
    "    print(f\"Recall (재현율): {recall_tfidf:.4f}\")\n",
    "    print(f\"Precision (정밀도): {precision_tfidf:.4f}\")\n",
    "    print(f\"F1-Score: {f1_score_tfidf:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# --- 6. 평균 점수 계산 및 출력 ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"--- 최종 평균 점수 (TF-IDF Top {top_n} 기반) ---\")\n",
    "if len(reference_reports) > 0:\n",
    "    # 평균 계산\n",
    "    avg_recall_tfidf = sum(all_recalls_tfidf) / len(all_recalls_tfidf)\n",
    "    avg_precision_tfidf = sum(all_precisions_tfidf) / len(all_precisions_tfidf)\n",
    "    avg_f1_tfidf = sum(all_f1_scores_tfidf) / len(all_f1_scores_tfidf)\n",
    "\n",
    "    # 사용된 보고서 이름 목록 생성\n",
    "    ref_names_str = ', '.join(reference_names)\n",
    "\n",
    "    print(f\"* 비교 대상 후보(B): {candidate_name}\")\n",
    "    print(f\"* 비교 기준 참조(A): {ref_names_str} ({len(reference_reports)}개)\")\n",
    "    print(f\"\\nAverage Recall:    {avg_recall_tfidf:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision_tfidf:.4f}\")\n",
    "    print(f\"Average F1-Score:  {avg_f1_tfidf:.4f}\")\n",
    "else:\n",
    "    print(\"비교할 참조 보고서가 없습니다.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n--- 중요 참고사항 ---\")\n",
    "print(f\"1. 이 평가는 각 보고서에서 TF-IDF 점수가 높은 **상위 {top_n}개 단어**를 '핵심 정보'로 간주하고 그 **겹침**을 비교한 결과입니다.\")\n",
    "print(f\"2. **`top_n` 값**을 어떻게 설정하느냐에 따라 결과가 크게 달라질 수 있습니다.\")\n",
    "print(\"3. TF-IDF는 단어의 **통계적 중요도**를 반영하지만, **문맥, 의미적 유사성, 동의어** 등은 고려하지 못합니다.\")\n",
    "print(\"4. 특히 한국어의 경우, **형태소 분석이나 불용어 처리**를 하지 않은 기본 TF-IDF는 조사, 어미 등 중요도가 낮은 단어가 높게 평가될 수 있어 결과 해석에 유의해야 합니다.\")\n",
    "print(\"5. 이 방법은 앞서 제시된 '명사 기반' 접근법과는 다른 관점(단어의 통계적 중요도)을 제공하며, 상호 보완적으로 결과를 해석하는 것이 좋습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 계산 중 (전체 문서 대상)...\n",
      "TF-IDF 계산 완료. 총 616개의 고유 단어 발견.\n",
      "\n",
      "--- 후보 보고서 (report_A_2) TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- 개별 참조 보고서와의 TF-IDF Top 50 포함도 평가 ---\n",
      "\n",
      "=== 비교: report_A_2 vs report_A_1 ===\n",
      "--- report_A_1 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 10\n",
      "\n",
      "[결과 for report_A_1]\n",
      "Recall (재현율): 0.2000\n",
      "Precision (정밀도): 0.2000\n",
      "F1-Score: 0.2000\n",
      "------------------------------\n",
      "\n",
      "=== 비교: report_A_2 vs report_A_3 ===\n",
      "--- report_A_3 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 11\n",
      "\n",
      "[결과 for report_A_3]\n",
      "Recall (재현율): 0.2200\n",
      "Precision (정밀도): 0.2200\n",
      "F1-Score: 0.2200\n",
      "------------------------------\n",
      "\n",
      "=== 비교: report_A_2 vs report_A_4 ===\n",
      "--- report_A_4 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 4\n",
      "\n",
      "[결과 for report_A_4]\n",
      "Recall (재현율): 0.0800\n",
      "Precision (정밀도): 0.0800\n",
      "F1-Score: 0.0800\n",
      "------------------------------\n",
      "\n",
      "==================================================\n",
      "--- 최종 평균 점수 (TF-IDF Top 50 기반) ---\n",
      "* 비교 대상 후보(B): report_A_2\n",
      "* 비교 기준 참조(A): report_A_1, report_A_3, report_A_4 (3개)\n",
      "\n",
      "Average Recall:    0.1667\n",
      "Average Precision: 0.1667\n",
      "Average F1-Score:  0.1667\n",
      "==================================================\n",
      "\n",
      "--- 중요 참고사항 ---\n",
      "1. 이 평가는 각 보고서에서 TF-IDF 점수가 높은 **상위 50개 단어**를 '핵심 정보'로 간주하고 그 **겹침**을 비교한 결과입니다.\n",
      "2. **`top_n` 값**을 어떻게 설정하느냐에 따라 결과가 크게 달라질 수 있습니다.\n",
      "3. TF-IDF는 단어의 **통계적 중요도**를 반영하지만, **문맥, 의미적 유사성, 동의어** 등은 고려하지 못합니다.\n",
      "4. 특히 한국어의 경우, **형태소 분석이나 불용어 처리**를 하지 않은 기본 TF-IDF는 조사, 어미 등 중요도가 낮은 단어가 높게 평가될 수 있어 결과 해석에 유의해야 합니다.\n",
      "5. 이 방법은 앞서 제시된 '명사 기반' 접근법과는 다른 관점(단어의 통계적 중요도)을 제공하며, 상호 보완적으로 결과를 해석하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np # numpy 배열 연산을 위해 필요\n",
    "\n",
    "# --- 1. 보고서 목록 및 이름 정의 ---\n",
    "candidate_report = report_A_2\n",
    "reference_reports = [report_A_1, report_A_3, report_A_4]\n",
    "\n",
    "# TF-IDF 계산을 위해 모든 문서를 하나의 리스트로 합칩니다.\n",
    "# 순서: 참조 보고서들 -> 후보 보고서\n",
    "all_documents = reference_reports + [candidate_report]\n",
    "\n",
    "# 각 문서의 이름을 저장합니다 (TF-IDF 매트릭스 인덱스와 순서 일치 중요).\n",
    "reference_names = [\"report_A_1\", \"report_A_3\", \"report_A_4\"]\n",
    "candidate_name = \"report_A_2\"\n",
    "all_doc_names = reference_names + [candidate_name]\n",
    "\n",
    "# 후보 보고서(B)가 all_documents 리스트에서 몇 번째 인덱스인지 확인합니다 (마지막).\n",
    "candidate_index = len(all_documents) - 1\n",
    "\n",
    "# --- 2. TF-IDF 계산 ---\n",
    "print(\"TF-IDF 계산 중 (전체 문서 대상)...\")\n",
    "# TfidfVectorizer 객체 생성 (한국어 전처리 추가 권장)\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit_transform: 모든 문서 기준 단어 사전 구축 및 TF-IDF 행렬 계산\n",
    "tfidf_matrix = vectorizer.fit_transform(all_documents)\n",
    "\n",
    "# 학습된 단어 목록\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"TF-IDF 계산 완료. 총 {len(feature_names)}개의 고유 단어 발견.\")\n",
    "\n",
    "# 결과를 보기 쉽게 DataFrame으로도 만들어 둡니다 (선택 사항, 주석 처리됨)\n",
    "# tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=all_doc_names, columns=feature_names)\n",
    "# print(\"--- 전체 TF-IDF 계산 결과 (DataFrame) ---\")\n",
    "# print(tfidf_df)\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# --- 3. TF-IDF 기반 핵심 정보(상위 N개 단어) 추출 함수 및 설정 ---\n",
    "\n",
    "# 각 보고서에서 TF-IDF 점수가 높은 상위 몇 개의 단어를 핵심 정보로 간주할지 설정\n",
    "top_n = 50 # 예시: 상위 100개 단어 사용 (필요에 따라 조절)\n",
    "\n",
    "def get_top_n_tfidf_terms(doc_index, tfidf_matrix, feature_names, top_n):\n",
    "    \"\"\"\n",
    "    주어진 문서 인덱스에 해당하는 TF-IDF 벡터에서 점수가 높은 상위 N개 단어 집합 반환.\n",
    "    \"\"\"\n",
    "    # 해당 문서의 TF-IDF 벡터 추출 (1차원 배열로 변환)\n",
    "    tfidf_vector = tfidf_matrix[doc_index].toarray().flatten()\n",
    "\n",
    "    # TF-IDF 점수 내림차순 정렬 시 원본 인덱스 가져오기\n",
    "    sorted_indices = np.argsort(tfidf_vector)[::-1]\n",
    "\n",
    "    # 상위 N개 인덱스 선택 (점수가 0보다 큰 경우만)\n",
    "    top_indices = [idx for idx in sorted_indices[:top_n] if tfidf_vector[idx] > 0]\n",
    "\n",
    "    # 해당 인덱스의 단어들을 집합(Set)으로 반환\n",
    "    top_terms = {feature_names[i] for i in top_indices}\n",
    "    return top_terms\n",
    "\n",
    "# --- 4. 후보 보고서(B)의 상위 N개 TF-IDF 단어 추출 (한 번만 수행) ---\n",
    "key_terms_B_tfidf = get_top_n_tfidf_terms(candidate_index, tfidf_matrix, feature_names, top_n)\n",
    "print(f\"\\n--- 후보 보고서 ({candidate_name}) TF-IDF Top {top_n} 단어 (총 {len(key_terms_B_tfidf)}개) ---\")\n",
    "# print(f\"{sorted(list(key_terms_B_tfidf))}\") # 필요시 단어 목록 출력 주석 해제\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# --- 5. 각 참조 보고서(A)와 비교 및 점수 계산 ---\n",
    "all_recalls_tfidf = []\n",
    "all_precisions_tfidf = []\n",
    "all_f1_scores_tfidf = []\n",
    "\n",
    "print(f\"--- 개별 참조 보고서와의 TF-IDF Top {top_n} 포함도 평가 ---\")\n",
    "# 참조 보고서들의 인덱스 (0부터 candidate_index - 1 까지) 순회\n",
    "for i in range(len(reference_reports)):\n",
    "    ref_name = all_doc_names[i]\n",
    "    print(f\"\\n=== 비교: {candidate_name} vs {ref_name} ===\")\n",
    "\n",
    "    # 현재 참조 보고서(A_i)의 상위 N개 TF-IDF 단어 추출\n",
    "    key_terms_A_tfidf = get_top_n_tfidf_terms(i, tfidf_matrix, feature_names, top_n)\n",
    "    print(f\"--- {ref_name} TF-IDF Top {top_n} 단어 (총 {len(key_terms_A_tfidf)}개) ---\")\n",
    "    # print(f\"{sorted(list(key_terms_A_tfidf))}\") # 필요시 단어 목록 출력 주석 해제\n",
    "\n",
    "    # 교집합: 두 보고서 모두에서 상위 N개 핵심 단어에 포함된 단어들\n",
    "    common_terms_tfidf = key_terms_A_tfidf.intersection(key_terms_B_tfidf)\n",
    "    print(f\"\\n* 공통 Top {top_n} 단어 수: {len(common_terms_tfidf)}\")\n",
    "    # if len(common_terms_tfidf) > 0: # 필요시 공통 단어 목록 출력 주석 해제\n",
    "    #     print(f\"  - 공통 단어 목록: {sorted(list(common_terms_tfidf))}\")\n",
    "\n",
    "    # Recall 계산: A의 Top N 중 B의 Top N에도 포함된 비율\n",
    "    if len(key_terms_A_tfidf) == 0:\n",
    "        recall_tfidf = 0.0\n",
    "    else:\n",
    "        recall_tfidf = len(common_terms_tfidf) / len(key_terms_A_tfidf)\n",
    "\n",
    "    # Precision 계산: B의 Top N 중 A의 Top N에도 포함된 비율\n",
    "    if len(key_terms_B_tfidf) == 0:\n",
    "        precision_tfidf = 0.0\n",
    "    else:\n",
    "        precision_tfidf = len(common_terms_tfidf) / len(key_terms_B_tfidf)\n",
    "\n",
    "    # F1-Score 계산\n",
    "    if (recall_tfidf + precision_tfidf) == 0:\n",
    "        f1_score_tfidf = 0.0\n",
    "    else:\n",
    "        f1_score_tfidf = 2 * (recall_tfidf * precision_tfidf) / (recall_tfidf + precision_tfidf)\n",
    "\n",
    "    # 결과 저장 및 개별 출력\n",
    "    all_recalls_tfidf.append(recall_tfidf)\n",
    "    all_precisions_tfidf.append(precision_tfidf)\n",
    "    all_f1_scores_tfidf.append(f1_score_tfidf)\n",
    "\n",
    "    print(f\"\\n[결과 for {ref_name}]\")\n",
    "    print(f\"Recall (재현율): {recall_tfidf:.4f}\")\n",
    "    print(f\"Precision (정밀도): {precision_tfidf:.4f}\")\n",
    "    print(f\"F1-Score: {f1_score_tfidf:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# --- 6. 평균 점수 계산 및 출력 ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"--- 최종 평균 점수 (TF-IDF Top {top_n} 기반) ---\")\n",
    "if len(reference_reports) > 0:\n",
    "    # 평균 계산\n",
    "    avg_recall_tfidf = sum(all_recalls_tfidf) / len(all_recalls_tfidf)\n",
    "    avg_precision_tfidf = sum(all_precisions_tfidf) / len(all_precisions_tfidf)\n",
    "    avg_f1_tfidf = sum(all_f1_scores_tfidf) / len(all_f1_scores_tfidf)\n",
    "\n",
    "    # 사용된 보고서 이름 목록 생성\n",
    "    ref_names_str = ', '.join(reference_names)\n",
    "\n",
    "    print(f\"* 비교 대상 후보(B): {candidate_name}\")\n",
    "    print(f\"* 비교 기준 참조(A): {ref_names_str} ({len(reference_reports)}개)\")\n",
    "    print(f\"\\nAverage Recall:    {avg_recall_tfidf:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision_tfidf:.4f}\")\n",
    "    print(f\"Average F1-Score:  {avg_f1_tfidf:.4f}\")\n",
    "else:\n",
    "    print(\"비교할 참조 보고서가 없습니다.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n--- 중요 참고사항 ---\")\n",
    "print(f\"1. 이 평가는 각 보고서에서 TF-IDF 점수가 높은 **상위 {top_n}개 단어**를 '핵심 정보'로 간주하고 그 **겹침**을 비교한 결과입니다.\")\n",
    "print(f\"2. **`top_n` 값**을 어떻게 설정하느냐에 따라 결과가 크게 달라질 수 있습니다.\")\n",
    "print(\"3. TF-IDF는 단어의 **통계적 중요도**를 반영하지만, **문맥, 의미적 유사성, 동의어** 등은 고려하지 못합니다.\")\n",
    "print(\"4. 특히 한국어의 경우, **형태소 분석이나 불용어 처리**를 하지 않은 기본 TF-IDF는 조사, 어미 등 중요도가 낮은 단어가 높게 평가될 수 있어 결과 해석에 유의해야 합니다.\")\n",
    "print(\"5. 이 방법은 앞서 제시된 '명사 기반' 접근법과는 다른 관점(단어의 통계적 중요도)을 제공하며, 상호 보완적으로 결과를 해석하는 것이 좋습니다.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 계산 중 (전체 문서 대상)...\n",
      "TF-IDF 계산 완료. 총 616개의 고유 단어 발견.\n",
      "\n",
      "--- 후보 보고서 (report_B) TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- 개별 참조 보고서와의 TF-IDF Top 50 포함도 평가 ---\n",
      "\n",
      "=== 비교: report_B vs report_A_1 ===\n",
      "--- report_A_1 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 5\n",
      "\n",
      "[결과 for report_A_1]\n",
      "Recall (재현율): 0.1000\n",
      "Precision (정밀도): 0.1000\n",
      "F1-Score: 0.1000\n",
      "------------------------------\n",
      "\n",
      "=== 비교: report_B vs report_A_2 ===\n",
      "--- report_A_2 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 4\n",
      "\n",
      "[결과 for report_A_2]\n",
      "Recall (재현율): 0.0800\n",
      "Precision (정밀도): 0.0800\n",
      "F1-Score: 0.0800\n",
      "------------------------------\n",
      "\n",
      "=== 비교: report_B vs report_A_3 ===\n",
      "--- report_A_3 TF-IDF Top 50 단어 (총 50개) ---\n",
      "\n",
      "* 공통 Top 50 단어 수: 10\n",
      "\n",
      "[결과 for report_A_3]\n",
      "Recall (재현율): 0.2000\n",
      "Precision (정밀도): 0.2000\n",
      "F1-Score: 0.2000\n",
      "------------------------------\n",
      "\n",
      "==================================================\n",
      "--- 최종 평균 점수 (TF-IDF Top 50 기반) ---\n",
      "* 비교 대상 후보(B): report_B\n",
      "* 비교 기준 참조(A): report_A_1, report_A_2, report_A_3, report_A_4 (3개)\n",
      "\n",
      "Average Recall:    0.1267\n",
      "Average Precision: 0.1267\n",
      "Average F1-Score:  0.1267\n",
      "==================================================\n",
      "\n",
      "--- 중요 참고사항 ---\n",
      "1. 이 평가는 각 보고서에서 TF-IDF 점수가 높은 **상위 50개 단어**를 '핵심 정보'로 간주하고 그 **겹침**을 비교한 결과입니다.\n",
      "2. **`top_n` 값**을 어떻게 설정하느냐에 따라 결과가 크게 달라질 수 있습니다.\n",
      "3. TF-IDF는 단어의 **통계적 중요도**를 반영하지만, **문맥, 의미적 유사성, 동의어** 등은 고려하지 못합니다.\n",
      "4. 특히 한국어의 경우, **형태소 분석이나 불용어 처리**를 하지 않은 기본 TF-IDF는 조사, 어미 등 중요도가 낮은 단어가 높게 평가될 수 있어 결과 해석에 유의해야 합니다.\n",
      "5. 이 방법은 앞서 제시된 '명사 기반' 접근법과는 다른 관점(단어의 통계적 중요도)을 제공하며, 상호 보완적으로 결과를 해석하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np # numpy 배열 연산을 위해 필요\n",
    "\n",
    "# --- 1. 보고서 목록 및 이름 정의 ---\n",
    "candidate_report = report_A_4\n",
    "reference_reports = [report_A_1, report_A_2, report_A_3]\n",
    "\n",
    "# TF-IDF 계산을 위해 모든 문서를 하나의 리스트로 합칩니다.\n",
    "# 순서: 참조 보고서들 -> 후보 보고서\n",
    "all_documents = reference_reports + [candidate_report]\n",
    "\n",
    "# 각 문서의 이름을 저장합니다 (TF-IDF 매트릭스 인덱스와 순서 일치 중요).\n",
    "reference_names = [\"report_A_1\", \"report_A_2\", \"report_A_3\", \"report_A_4\"]\n",
    "candidate_name = \"report_B\"\n",
    "all_doc_names = reference_names + [candidate_name]\n",
    "\n",
    "# 후보 보고서(B)가 all_documents 리스트에서 몇 번째 인덱스인지 확인합니다 (마지막).\n",
    "candidate_index = len(all_documents) - 1\n",
    "\n",
    "# --- 2. TF-IDF 계산 ---\n",
    "print(\"TF-IDF 계산 중 (전체 문서 대상)...\")\n",
    "# TfidfVectorizer 객체 생성 (한국어 전처리 추가 권장)\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit_transform: 모든 문서 기준 단어 사전 구축 및 TF-IDF 행렬 계산\n",
    "tfidf_matrix = vectorizer.fit_transform(all_documents)\n",
    "\n",
    "# 학습된 단어 목록\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"TF-IDF 계산 완료. 총 {len(feature_names)}개의 고유 단어 발견.\")\n",
    "\n",
    "# 결과를 보기 쉽게 DataFrame으로도 만들어 둡니다 (선택 사항, 주석 처리됨)\n",
    "# tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=all_doc_names, columns=feature_names)\n",
    "# print(\"--- 전체 TF-IDF 계산 결과 (DataFrame) ---\")\n",
    "# print(tfidf_df)\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# --- 3. TF-IDF 기반 핵심 정보(상위 N개 단어) 추출 함수 및 설정 ---\n",
    "\n",
    "# 각 보고서에서 TF-IDF 점수가 높은 상위 몇 개의 단어를 핵심 정보로 간주할지 설정\n",
    "top_n = 50 # 예시: 상위 100개 단어 사용 (필요에 따라 조절)\n",
    "\n",
    "def get_top_n_tfidf_terms(doc_index, tfidf_matrix, feature_names, top_n):\n",
    "    \"\"\"\n",
    "    주어진 문서 인덱스에 해당하는 TF-IDF 벡터에서 점수가 높은 상위 N개 단어 집합 반환.\n",
    "    \"\"\"\n",
    "    # 해당 문서의 TF-IDF 벡터 추출 (1차원 배열로 변환)\n",
    "    tfidf_vector = tfidf_matrix[doc_index].toarray().flatten()\n",
    "\n",
    "    # TF-IDF 점수 내림차순 정렬 시 원본 인덱스 가져오기\n",
    "    sorted_indices = np.argsort(tfidf_vector)[::-1]\n",
    "\n",
    "    # 상위 N개 인덱스 선택 (점수가 0보다 큰 경우만)\n",
    "    top_indices = [idx for idx in sorted_indices[:top_n] if tfidf_vector[idx] > 0]\n",
    "\n",
    "    # 해당 인덱스의 단어들을 집합(Set)으로 반환\n",
    "    top_terms = {feature_names[i] for i in top_indices}\n",
    "    return top_terms\n",
    "\n",
    "# --- 4. 후보 보고서(B)의 상위 N개 TF-IDF 단어 추출 (한 번만 수행) ---\n",
    "key_terms_B_tfidf = get_top_n_tfidf_terms(candidate_index, tfidf_matrix, feature_names, top_n)\n",
    "print(f\"\\n--- 후보 보고서 ({candidate_name}) TF-IDF Top {top_n} 단어 (총 {len(key_terms_B_tfidf)}개) ---\")\n",
    "# print(f\"{sorted(list(key_terms_B_tfidf))}\") # 필요시 단어 목록 출력 주석 해제\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# --- 5. 각 참조 보고서(A)와 비교 및 점수 계산 ---\n",
    "all_recalls_tfidf = []\n",
    "all_precisions_tfidf = []\n",
    "all_f1_scores_tfidf = []\n",
    "\n",
    "print(f\"--- 개별 참조 보고서와의 TF-IDF Top {top_n} 포함도 평가 ---\")\n",
    "# 참조 보고서들의 인덱스 (0부터 candidate_index - 1 까지) 순회\n",
    "for i in range(len(reference_reports)):\n",
    "    ref_name = all_doc_names[i]\n",
    "    print(f\"\\n=== 비교: {candidate_name} vs {ref_name} ===\")\n",
    "\n",
    "    # 현재 참조 보고서(A_i)의 상위 N개 TF-IDF 단어 추출\n",
    "    key_terms_A_tfidf = get_top_n_tfidf_terms(i, tfidf_matrix, feature_names, top_n)\n",
    "    print(f\"--- {ref_name} TF-IDF Top {top_n} 단어 (총 {len(key_terms_A_tfidf)}개) ---\")\n",
    "    # print(f\"{sorted(list(key_terms_A_tfidf))}\") # 필요시 단어 목록 출력 주석 해제\n",
    "\n",
    "    # 교집합: 두 보고서 모두에서 상위 N개 핵심 단어에 포함된 단어들\n",
    "    common_terms_tfidf = key_terms_A_tfidf.intersection(key_terms_B_tfidf)\n",
    "    print(f\"\\n* 공통 Top {top_n} 단어 수: {len(common_terms_tfidf)}\")\n",
    "    # if len(common_terms_tfidf) > 0: # 필요시 공통 단어 목록 출력 주석 해제\n",
    "    #     print(f\"  - 공통 단어 목록: {sorted(list(common_terms_tfidf))}\")\n",
    "\n",
    "    # Recall 계산: A의 Top N 중 B의 Top N에도 포함된 비율\n",
    "    if len(key_terms_A_tfidf) == 0:\n",
    "        recall_tfidf = 0.0\n",
    "    else:\n",
    "        recall_tfidf = len(common_terms_tfidf) / len(key_terms_A_tfidf)\n",
    "\n",
    "    # Precision 계산: B의 Top N 중 A의 Top N에도 포함된 비율\n",
    "    if len(key_terms_B_tfidf) == 0:\n",
    "        precision_tfidf = 0.0\n",
    "    else:\n",
    "        precision_tfidf = len(common_terms_tfidf) / len(key_terms_B_tfidf)\n",
    "\n",
    "    # F1-Score 계산\n",
    "    if (recall_tfidf + precision_tfidf) == 0:\n",
    "        f1_score_tfidf = 0.0\n",
    "    else:\n",
    "        f1_score_tfidf = 2 * (recall_tfidf * precision_tfidf) / (recall_tfidf + precision_tfidf)\n",
    "\n",
    "    # 결과 저장 및 개별 출력\n",
    "    all_recalls_tfidf.append(recall_tfidf)\n",
    "    all_precisions_tfidf.append(precision_tfidf)\n",
    "    all_f1_scores_tfidf.append(f1_score_tfidf)\n",
    "\n",
    "    print(f\"\\n[결과 for {ref_name}]\")\n",
    "    print(f\"Recall (재현율): {recall_tfidf:.4f}\")\n",
    "    print(f\"Precision (정밀도): {precision_tfidf:.4f}\")\n",
    "    print(f\"F1-Score: {f1_score_tfidf:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# --- 6. 평균 점수 계산 및 출력 ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"--- 최종 평균 점수 (TF-IDF Top {top_n} 기반) ---\")\n",
    "if len(reference_reports) > 0:\n",
    "    # 평균 계산\n",
    "    avg_recall_tfidf = sum(all_recalls_tfidf) / len(all_recalls_tfidf)\n",
    "    avg_precision_tfidf = sum(all_precisions_tfidf) / len(all_precisions_tfidf)\n",
    "    avg_f1_tfidf = sum(all_f1_scores_tfidf) / len(all_f1_scores_tfidf)\n",
    "\n",
    "    # 사용된 보고서 이름 목록 생성\n",
    "    ref_names_str = ', '.join(reference_names)\n",
    "\n",
    "    print(f\"* 비교 대상 후보(B): {candidate_name}\")\n",
    "    print(f\"* 비교 기준 참조(A): {ref_names_str} ({len(reference_reports)}개)\")\n",
    "    print(f\"\\nAverage Recall:    {avg_recall_tfidf:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision_tfidf:.4f}\")\n",
    "    print(f\"Average F1-Score:  {avg_f1_tfidf:.4f}\")\n",
    "else:\n",
    "    print(\"비교할 참조 보고서가 없습니다.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n--- 중요 참고사항 ---\")\n",
    "print(f\"1. 이 평가는 각 보고서에서 TF-IDF 점수가 높은 **상위 {top_n}개 단어**를 '핵심 정보'로 간주하고 그 **겹침**을 비교한 결과입니다.\")\n",
    "print(f\"2. **`top_n` 값**을 어떻게 설정하느냐에 따라 결과가 크게 달라질 수 있습니다.\")\n",
    "print(\"3. TF-IDF는 단어의 **통계적 중요도**를 반영하지만, **문맥, 의미적 유사성, 동의어** 등은 고려하지 못합니다.\")\n",
    "print(\"4. 특히 한국어의 경우, **형태소 분석이나 불용어 처리**를 하지 않은 기본 TF-IDF는 조사, 어미 등 중요도가 낮은 단어가 높게 평가될 수 있어 결과 해석에 유의해야 합니다.\")\n",
    "print(\"5. 이 방법은 앞서 제시된 '명사 기반' 접근법과는 다른 관점(단어의 통계적 중요도)을 제공하며, 상호 보완적으로 결과를 해석하는 것이 좋습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
